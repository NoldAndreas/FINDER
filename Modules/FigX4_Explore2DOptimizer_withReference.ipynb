{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Definitions import basefolder\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Finder_1d import Finder_1d\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as dist\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from Clustering_CAML import Clustering_CAML\n",
    "import h5py\n",
    "from DbscanLoop import DbscanLoop\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "#import feather\n",
    "#import pyarrow.feather as feather\n",
    "#import rpy2.robjects as ro\n",
    "#from rpy2.robjects import pandas2ri\n",
    "#from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "#from rpy2.robjects import pandas2ri\n",
    "#from rpy2.robjects.conversion import localconverter\n",
    "#from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotScatter(XC_,labels=[],ax=[]):\n",
    "\n",
    "    if(len(labels)==0):\n",
    "        labels = -1*np.ones((len(XC_),));\n",
    " \n",
    "    if(ax==[]):\n",
    "        fig,ax = plt.subplots(1,1,figsize=(6,6)); \n",
    "       \n",
    "    mark_ = (labels==-1);\n",
    "    ax.scatter(x=XC_[mark_,0],y=XC_[mark_,1],s=.4,c='grey',alpha=0.1);\n",
    "\n",
    "    mark_ = (labels>=0);\n",
    "    sns.scatterplot(x=XC_[mark_,0],y=XC_[mark_,1],hue=labels[mark_],palette='deep',linewidth=0,\n",
    "                    s=2,legend=False,ax=ax);\n",
    "    ax.set_aspect('equal');\n",
    "#    plt.savefig(outputfolder+\"results_\"+analysis_name+\"_\"+filename_add+\".pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadPoints(filename,datascale=1):\n",
    "    if(filename[-3:]==\"txt\"):\n",
    "        XC = np.loadtxt(filename);\n",
    "    elif(filename[-4:]==\"hdf5\"):\n",
    "        f             = h5py.File(filename, 'r')    \n",
    "        dset          = f['locs'];\n",
    "        XC            = np.stack((dset[\"x\"],dset[\"y\"])).T    \n",
    "        \n",
    "    XC        = np.unique(XC,axis=0);\n",
    "    XC        = datascale*XC;\n",
    "        \n",
    "    return XC;\n",
    "\n",
    "def FilterPoints(XC,xmin,xmax,ymin,ymax):\n",
    "    mask = (XC[:,0]>xmin)*(XC[:,0]<xmax)*(XC[:,1]>ymin)*(XC[:,1]<ymax);\n",
    "    return XC[mask,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetLineOfOptima(df,x_selector,y_selector,no_bins=0):\n",
    "    \n",
    "    x_sel      = df[x_selector];\n",
    "    x_sel_sort = np.sort(np.unique(x_sel));\n",
    "    \n",
    "    if(no_bins == 0):\n",
    "        bins = np.asarray([np.min(x_sel)-1]+list((x_sel_sort[:-1]+x_sel_sort[1:])/2)+[np.max(x_sel)+1]);\n",
    "        no_bins = len(bins)-1;\n",
    "    else:\n",
    "        bins = np.linspace(0.99*np.min(x_sel),np.max(x_sel)*1.01,no_bins+1);\n",
    "    print(np.unique(df[x_selector]));    \n",
    "\n",
    "    xs = -1*np.ones((no_bins,1),dtype=int);\n",
    "    idxs = [];\n",
    "    \n",
    "    for i in np.arange(no_bins):\n",
    "        mark_    = (df[x_selector] > bins[i])&(df[x_selector] <= bins[i+1]);\n",
    "        if(np.sum(mark_)==0):\n",
    "            continue;\n",
    "        else:\n",
    "            idxs.append((df.loc[mark_,y_selector]).idxmax());\n",
    "        \n",
    "    df_opt             = pd.DataFrame();\n",
    "    df_opt['idx']      = idxs;\n",
    "    for c in df.columns:\n",
    "        df_opt[c] = np.asarray(df.loc[idxs,c]);\n",
    "\n",
    "    return df_opt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetLineOfOptimaUnique(df,x_selector,y_selector,no_bins=0):\n",
    "    \n",
    "    x_sel_sort = np.sort(np.unique(df[x_selector]));    \n",
    "    idxs       = [];\n",
    "    \n",
    "    for x_sel in x_sel_sort:\n",
    "        mark_    = (df[x_selector] == x_sel);\n",
    "        if(np.sum(mark_)==0):\n",
    "            continue;\n",
    "        else:\n",
    "            idxs.append((df.loc[mark_,y_selector]).idxmax());\n",
    "        \n",
    "    df_opt             = pd.DataFrame();\n",
    "    df_opt['idx']      = idxs;\n",
    "    for c in df.columns:\n",
    "        df_opt[c] = np.asarray(df.loc[idxs,c]);\n",
    "\n",
    "    return df_opt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetClusterDistribution(labels):\n",
    "    cl_sizes = [];\n",
    "    for c in np.unique(labels):\n",
    "        if(c == -1):\n",
    "            continue;\n",
    "        cl_sizes.append(np.sum(labels==c));\n",
    "    return cl_sizes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and Load points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    mainfolder     = '/Users/andreas/Documents/NoiseRecognizer_WorkingVersion/ProteinData_ttx_1hr_2/';    \n",
    "    analysis_name  = \"dataWindow_2\";\n",
    "    image_filename = \"AHA_2_MMStack_Pos0.ome_locs_render_driftcor_filter_render_pix0.02X6f20\";\n",
    "\n",
    "    XC        = LoadPoints(mainfolder+image_filename+'.hdf5',datascale=158);    \n",
    "    XC_signal = FilterPoints(XC,22000,27000,22000,27000);\n",
    "    XC_noise  = FilterPoints(XC,60000,70000,50000,60000);\n",
    "\n",
    "elif(True):\n",
    "    mainfolder       = '/Users/andreas/Documents/NoiseRecognizer_WorkingVersion/MikeData/';    \n",
    "    image_filename   = 'EGFR-P1-ATTO655_cell_2_MMImages.ome_locs_render_al_linked1sigma_X';\n",
    "    \n",
    "    if(True):\n",
    "        analysis_name = \"dataWindow_1\";    \n",
    "        algo          = \"DbscanLoop\"\n",
    "    else:    \n",
    "        analysis_name = \"dataWindow_1_dbscan\";    \n",
    "        algo          = \"dbscan\"\n",
    "    \n",
    "    XC_noise     = LoadPoints(mainfolder+image_filename+'_noise.txt');\n",
    "    XC_signal    = LoadPoints(mainfolder+image_filename+'_signal.txt');    \n",
    "    \n",
    "    XC_noise  = FilterPoints(XC_noise,50,60,50,60)\n",
    "    XC_signal = FilterPoints(XC_signal,100,110,150,160)    \n",
    "    #Define window to analyse\n",
    "    \n",
    "outputfolder   = mainfolder + 'Analysis/';    \n",
    "outputfolder_R = mainfolder + 'Output_R/';\n",
    "save_name      = outputfolder+analysis_name;\n",
    "np.savetxt(save_name+\"_filtered_noise.txt\",XC_noise,fmt=\"%f\\t%f\");\n",
    "np.savetxt(save_name+\"_filtered_signal.txt\",XC_signal,fmt=\"%f\\t%f\");    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XC_noise     = LoadPoints(mainfolder+'EGFR-P1-ATTO655_cell_2_MMImages.ome_locs_render_al_linked1sigma_X_noise.txt');\n",
    "#XC_noise  = FilterPoints(XC_noise,60,80,60,80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load or compute clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "PlotScatter(XC_signal,ax=axs[0])\n",
    "PlotScatter(XC_noise,ax=axs[1])\n",
    "#np.savetxt(outputfolder_R+analysis_name+\"_filtered_signal.txt\",XC_signal,fmt=\"%f\\t%f\");    \n",
    "axs[0].set_title('signal');\n",
    "axs[1].set_title('noise');\n",
    "\n",
    "plt.savefig(save_name+\"_localizations_signal_vs_noise.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(False):\n",
    "    FD      = Finder_1d(algo=algo);\n",
    "    labels  = FD.fit(XC_signal);    \n",
    "    \n",
    "    FD_ref      = Finder_1d(algo=algo);\n",
    "    labels_ref  = FD_ref.fit(XC_noise,XC_signal);    \n",
    "    \n",
    "    with open(outputfolder+\"results_\"+analysis_name+'.pickle','wb') as handle:\n",
    "        pickle.dump({'FD':FD,'FD_ref':FD_ref}, handle,protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "else:\n",
    "    with open(outputfolder+'results_'+analysis_name+'.pickle', 'rb') as fr:\n",
    "        FD_load = pickle.load(fr);\n",
    "    FD     = FD_load['FD'];\n",
    "    FD_ref = FD_load['FD_ref'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save for input in R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save phasespace in csv\n",
    "FD_all1 = (FD.phasespace);\n",
    "FD_all1['type'] = 'signal';\n",
    "\n",
    "FD_all2         = (FD_ref.phasespace);\n",
    "FD_all2['type'] = 'noise';\n",
    "\n",
    "(FD_all1.append(FD_all2,ignore_index=True)).to_csv(outputfolder_R+'results_'+analysis_name+'.csv');\n",
    "#(FD.phasespace).to_csv(outputfolder+'results_phasespace'+analysis_name+'.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.zeros((len((FD.phasespace).loc[1,'labels']),len(FD.phasespace)),dtype=np.int32)\n",
    "for i,d in enumerate(FD.phasespace['labels']):\n",
    "    L[:,i] = d;\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_labels_signal.txt\",L,fmt=\"%d\",delimiter='\\t',newline='\\n');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.zeros((len((FD_ref.phasespace).loc[1,'labels']),len(FD_ref.phasespace)),dtype=np.int32)\n",
    "for i,d in enumerate(FD_ref.phasespace['labels']):\n",
    "    L[:,i] = d;\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_labels_noise.txt\",L,fmt=\"%d\",delimiter='\\t',newline='\\n');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(outputfolder_R+analysis_name+\"_filtered_noise.txt\",XC_noise,fmt=\"%f\\t%f\");\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_filtered_signal.txt\",XC_signal,fmt=\"%f\\t%f\");    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_distribution = [];\n",
    "ind = np.zeros((0,),dtype=int);\n",
    "for i,d in enumerate(FD.phasespace['labels']):\n",
    "    d_ = GetClusterDistribution(d);\n",
    "    cls_distribution += (d_);\n",
    "    ind = np.concatenate((ind,i*np.ones_like(d_,dtype=int)))\n",
    "    \n",
    "cls_d = pd.DataFrame();\n",
    "cls_d['size'] = cls_distribution\n",
    "cls_d['index'] = (ind);\n",
    "cls_d.to_csv(outputfolder_R+analysis_name+\"_clusterSizes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(outputfolder_R+analysis_name+\"_clusterSizes.txt\", \"w\") as txt_file:\n",
    "#    for i,d in enumerate(FD.phasespace['labels']):\n",
    "#        d_ = GetClusterDistribution(d);\n",
    "#        txt_file.write(' '.join(str(x) for x in d_)+'\\n') # works with any number of el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a clustering:\n",
    "df1     = FD.phasespace[['sigma', 'threshold','similarityScore','no_clusters']];\n",
    "df1_ref = FD_ref.phasespace[['sigma', 'threshold','similarityScore','no_clusters']];\n",
    "\n",
    "df1['similarityScore_ref']       = df1_ref['similarityScore'];\n",
    "df1['similarityScore_ref_ratio'] = (df1_ref['similarityScore'])/(df1['similarityScore']);\n",
    "\n",
    "df1['no_clusters_ref']       = df1_ref['no_clusters'];\n",
    "df1['no_clusters_ref_ratio'] = (df1_ref['no_clusters'])/(df1['no_clusters']);\n",
    "\n",
    "df_opt_sim = GetLineOfOptima(df1,'similarityScore_ref','similarityScore',15);\n",
    "df_opt_cl  = GetLineOfOptima(df1,'no_clusters_ref','no_clusters',15);\n",
    "\n",
    "if(False):\n",
    "    limit_noise_to_signal = 0.4;\n",
    "    \n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['similarityScore_ref_ratio'] < limit_noise_to_signal);\n",
    "    idx_similarityScore  = (df1.loc[mark_,'similarityScore']).idxmax();\n",
    "#    print(df1.loc[idx_similarityScore,:])\n",
    "\n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['no_clusters_ref_ratio'] < limit_noise_to_signal);\n",
    "    idx_no_clusters  = (df1.loc[mark_,'no_clusters']).idxmax();\n",
    "#    print(df1.loc[idx_no_clusters,:])\n",
    "else:\n",
    "    limit_noise_no_cluster = 4;    \n",
    "    limit_noise_similarity = 320;\n",
    "        \n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['similarityScore_ref'] < limit_noise_similarity);\n",
    "    idx_similarityScore  = (df1.loc[mark_,'similarityScore']).idxmax();\n",
    "#    print(df1.loc[idx_similarityScore,:])\n",
    "\n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['no_clusters_ref'] < limit_noise_no_cluster);\n",
    "    idx_no_clusters  = (df1.loc[mark_,'no_clusters']).idxmax();\n",
    "#    print(df1.loc[idx_no_clusters,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(13,13)); \n",
    "PlotScatter(XC_signal,FD.phasespace.loc[idx_similarityScore,'labels'],ax=axs[0,0])\n",
    "PlotScatter(XC_signal,FD.phasespace.loc[idx_no_clusters,'labels'],ax=axs[0,1])\n",
    "\n",
    "PlotScatter(XC_noise,FD_ref.phasespace.loc[idx_similarityScore,'labels'],ax=axs[1,0])\n",
    "PlotScatter(XC_noise,FD_ref.phasespace.loc[idx_no_clusters,'labels'],ax=axs[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='similarityScore_ref',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "ax.scatter(df1.loc[idx_similarityScore,'similarityScore_ref'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "ax.scatter(df1.loc[idx_no_clusters,'similarityScore_ref'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "sns.lineplot(data=df_opt_sim,x='similarityScore_ref',y=\"similarityScore\",color='r',ax=ax)\n",
    "sns.lineplot(data=df_opt_cl,x='similarityScore_ref',y=\"similarityScore\",color='b',ax=ax)\n",
    "ax.set_title('ordered by similarity score');\n",
    "\n",
    "ax      = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "sns.lineplot(data=df_opt_sim,x='no_clusters_ref',y=\"no_clusters\",ax=ax,color='r')\n",
    "sns.lineplot(data=df_opt_cl,x='no_clusters_ref',y=\"no_clusters\",ax=ax,color='b')\n",
    "ax.set_title('ordered by no of clusters');\n",
    "\n",
    "plt.savefig(save_name+\"_phasespace_ordered.pdf\",bbox_inches=\"tight\");\n",
    "#ax.set_xlim(-10,2000);\n",
    "#ax.set_xlim(0,30);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetClusterSizesAlongOptima(df1_):\n",
    "    df_opt_th = GetLineOfOptima(df1_,'threshold','similarityScore')\n",
    "\n",
    "    cl_dist = [];\n",
    "    idxs = [];\n",
    "    thresholds = [];\n",
    "\n",
    "    for index, row in df_opt_th.iterrows():\n",
    "        df1_row     = FD.phasespace.loc[int(row['idx']),:];\n",
    "        cld         = GetClusterDistribution(df1_row['labels']);\n",
    "        cl_dist    += (list(cld));\n",
    "        idxs       += list((int(row['idx']))*np.ones_like(cld));\n",
    "        thresholds += list(df1_row['threshold']*np.ones_like(cld));\n",
    "\n",
    "    df_clusterSizes = pd.DataFrame();\n",
    "    df_clusterSizes['clusterSize'] = cl_dist;\n",
    "    df_clusterSizes['threshold']   = thresholds;\n",
    "    \n",
    "    return df_clusterSizes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes     = GetClusterSizesAlongOptima(df1);\n",
    "df_clusterSizes_ref = GetClusterSizesAlongOptima(df1_ref);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalyseClusterSizes(df_clusterSizes_,name):\n",
    "    \n",
    "    th_ = [];\n",
    "    cv_ = [];\n",
    "    fano_ = [];\n",
    "    kur_ = [];\n",
    "    skew_ = [];\n",
    "    max_cl = [];\n",
    "    m_ = [];\n",
    "    med_ = [];\n",
    "    v1_ = [];\n",
    "\n",
    "    fig,axs = plt.subplots(1,1,figsize=(3,3)); \n",
    "    for t in np.unique(df_clusterSizes_['threshold']):#df_clusterSizes.iterrows():\n",
    "        d_ = df_clusterSizes_.loc[df_clusterSizes_['threshold']==t,'clusterSize'];\n",
    "        cv_.append(stats.variation(d_));\n",
    "        m_.append(np.mean(d_));\n",
    "        med_.append(np.median(d_));    \n",
    "        th_.append(t);\n",
    "        fano_.append(np.var(d_)/np.mean(d_));\n",
    "        kur_.append(stats.kurtosis(d_));                            \n",
    "        skew_.append(stats.skew(d_));    \n",
    "\n",
    "\n",
    "        z_ = plt.hist(d_,bins=np.linspace(0,40,41)+0.5);\n",
    "        idx_max = np.argmax(z_[0]);    \n",
    "        max_cl.append(z_[1][idx_max]+0.5);\n",
    "\n",
    "        dv_ = d_.value_counts().sort_index();    \n",
    "        v1  = np.sum(dv_[(dv_.index < t+1)]);#/np.sum(dv_[(dv_.index < t+3)]);\n",
    "    #    v1 = np.sum(dv_[(dv_.index < t+2)])/np.sum(dv_[(dv_.index >= t+2)*(dv_.index < t+4)]);    \n",
    "        v1_.append(v1);\n",
    "\n",
    "\n",
    "    #    v1.append(np.sum(dv_[(dv_.index < th+1)])/np.sum(dv_[(dv_.index < th+3)]));\n",
    "\n",
    "\n",
    "    df_stats_per_th = pd.DataFrame();\n",
    "    df_stats_per_th['mean'] = m_;\n",
    "    df_stats_per_th['median'] = med_;\n",
    "    df_stats_per_th['cv'] = cv_;\n",
    "    df_stats_per_th['threshold']   = th_;\n",
    "    df_stats_per_th['fano']   = fano_;\n",
    "    df_stats_per_th['skewness']   = skew_;\n",
    "    df_stats_per_th['kurtosis']   = kur_;\n",
    "    df_stats_per_th['max_cl']   = max_cl;\n",
    "    df_stats_per_th['firstBin']   = v1_;\n",
    "    \n",
    "    \n",
    "    fig,axs = plt.subplots(3,2,figsize=(12,12)); \n",
    "    sns.lineplot(df_stats_per_th['threshold'],df_stats_per_th['cv'],label='cv',ax=axs[0,0]);\n",
    "    sns.lineplot(df_stats_per_th['threshold'],df_stats_per_th['fano'],label='fano',ax=axs[0,1]);\n",
    "    sns.lineplot(df_stats_per_th['threshold'],df_stats_per_th['skewness'],label='skewness',ax=axs[1,0]);\n",
    "    sns.lineplot(df_stats_per_th['threshold'],df_stats_per_th['kurtosis'],label='kurtosis',ax=axs[1,1]);\n",
    "\n",
    "    sns.lineplot(df_stats_per_th['threshold'],df_stats_per_th['median'],label='median',ax=axs[2,0]);\n",
    "    sns.lineplot(df_stats_per_th['threshold'],df_stats_per_th['firstBin'],label='firstBin',ax=axs[2,1]);\n",
    "\n",
    "    plt.savefig(save_name+\"_phasespace_alongLineOfOptima_\"+name+\".pdf\",bbox_inches=\"tight\");\n",
    "\n",
    "    return df_stats_per_th;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: Did we reach a plateau?\n",
    "def Plateau_analysis(x,y):    \n",
    "    x =np.asarray(x);\n",
    "    y =np.asarray(y);    \n",
    "    \n",
    "    y = 0.5*(y[1:]+y[:-1]);\n",
    "    x = 0.5*(x[1:]+x[:-1]);    \n",
    "    \n",
    "    dydx = (y[1:]-y[:-1])/(x[1:]-x[:-1]);\n",
    "#    print(dydx)\n",
    "#    print(y)\n",
    "    plt.plot(x[1:],dydx/y[0],'r');\n",
    "#    plt.plot(x,y,'b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plateau_analysis(df_stats_per_th['threshold'],df_stats_per_th['firstBin'])\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_th = AnalyseClusterSizes(df_clusterSizes,'signal');\n",
    "df_stats_per_th = AnalyseClusterSizes(df_clusterSizes_ref,'ref');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df_stats_per_th['kurtosis'];\n",
    "sns.lineplot(df_stats_per_th['threshold'][1:],np.abs(np.asarray(z[1:])-np.asarray(z[:-1])),label='kurtosis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(np.max(df_clusterSizes['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotDistribution(df_,name):\n",
    "    fig,axs = plt.subplots(1,1,figsize=(10,10)); \n",
    "    sns.stripplot(data=df_,y='clusterSize',x='threshold',ax=axs)\n",
    "    sns.boxplot(data=df_,y='clusterSize',x='threshold',ax=axs,color='lightgrey')\n",
    "    axs.set_ylim(0,80)\n",
    "    plt.plot(np.arange(len(np.unique(df_['threshold']))),np.unique(df_clusterSizes['threshold']))\n",
    "\n",
    "    plt.savefig(save_name+\"_clusterDistribution_alongLineOfOptima_\"+name+\".pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotDistribution(df_clusterSizes,'signal');\n",
    "PlotDistribution(df_clusterSizes_ref,'ref');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_clusterSizes.loc[df_clusterSizes['threshold']==11,'clusterSize'],bins=np.linspace(0,100,101)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_th = GetLineOfOptima(df1,'threshold','similarityScore')\n",
    "\n",
    "for th in np.unique(df_opt_th['threshold']):\n",
    "    idx_ = int(df_opt_th.loc[df_opt_th['threshold']==th,'idx'])\n",
    "\n",
    "    fig,axs = plt.subplots(1,2,figsize=(13,8)); \n",
    "    PlotScatter(XC_signal,FD.phasespace.loc[idx_,'labels'],ax=axs[0])\n",
    "    #PlotScatter(XC_signal,FD.phasespace.loc[133,'labels'],ax=axs[1])\n",
    "    PlotScatter(XC_noise,FD_ref.phasespace.loc[idx_,'labels'],ax=axs[1])\n",
    "    axs[0].set_title('signal');\n",
    "    axs[1].set_title('noise');\n",
    "    plt.savefig(save_name+\"_OptimalClustering_threshold_\"+str(th)+\".pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_th = GetLineOfOptima(df1,'threshold','similarityScore')\n",
    "df_opt_th_ncl = GetLineOfOptima(df1,'threshold','no_clusters')\n",
    "\n",
    "fig,axs = plt.subplots(3,3,figsize=(14,14));\n",
    "\n",
    "ax = axs[0,0];\n",
    "ax.plot(df_opt_th['sigma'],df_opt_th['threshold']);\n",
    "sns.scatterplot(x=df_opt_th['sigma'],y=df_opt_th['threshold'],hue=df_opt_th['no_clusters_ref_ratio'],s=100,ax=ax);\n",
    "\n",
    "ax.plot(df_opt_th_ncl['sigma'],df_opt_th_ncl['threshold'],'r');\n",
    "sns.scatterplot(x=df_opt_th_ncl['sigma'],y=df_opt_th['threshold'],hue=df_opt_th['no_clusters_ref_ratio'],\\\n",
    "                s=100,ax=ax,palette='Reds');\n",
    "\n",
    "ax.set_xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "ax.set_ylim(np.min(df1['threshold']),np.max(df1['threshold']))\n",
    "\n",
    "ax = axs[0,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore_ref_ratio',ax=ax);\n",
    "sns.lineplot(data=df_opt_th_ncl,x='threshold',y='similarityScore_ref_ratio',ax=ax,color='r');\n",
    "\n",
    "ax = axs[0,2];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters_ref_ratio',ax=ax);\n",
    "sns.lineplot(data=df_opt_th_ncl,x='threshold',y='no_clusters_ref_ratio',ax=ax,color='r');\n",
    "\n",
    "ax = axs[1,0];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['no_clusters']));\n",
    "\n",
    "ax = axs[1,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters_ref',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['no_clusters_ref']));\n",
    "\n",
    "ax = axs[1,2];\n",
    "sns.lineplot(data=df_opt_th,x='no_clusters',y='no_clusters_ref',ax=ax);\n",
    "\n",
    "ax = axs[2,0];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['similarityScore']));\n",
    "\n",
    "ax = axs[2,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore_ref',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['similarityScore_ref']));\n",
    "\n",
    "ax = axs[2,2];\n",
    "sns.lineplot(data=df_opt_th,x='similarityScore',y='similarityScore_ref',ax=ax);\n",
    "\n",
    "plt.savefig(save_name+\"_Analysis_alongLineOfOptima.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_opt_sim['sigma'],df_opt_sim['threshold']);\n",
    "sns.scatterplot(x=df_opt_sim['sigma'],y=df_opt_sim['threshold'],hue=df_opt_sim['similarityScore'],s=100);\n",
    "plt.xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "plt.ylim(np.min(df1['threshold']),np.max(df1['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_opt_cl['sigma'],df_opt_cl['threshold']);\n",
    "sns.scatterplot(x=df_opt_cl['sigma'],y=df_opt_cl['threshold'],hue=df_opt_cl['no_clusters'],s=100);\n",
    "plt.xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "plt.ylim(np.min(df1['threshold']),np.max(df1['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='similarityScore_ref_ratio',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "ax.scatter(df1.loc[idx_similarityScore,'similarityScore_ref_ratio'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "ax.scatter(df1.loc[idx_no_clusters,'similarityScore_ref_ratio'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "ax.set_xlim(0,1);\n",
    "#ax.set_ylim(-10,4000);\n",
    "\n",
    "ax = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref_ratio',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref_ratio'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref_ratio'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "ax.set_xlim(0,0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "#ax.set_xlim(-10,2000);\n",
    "#ax.set_ylim(-10,4000);\n",
    "\n",
    "ax = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "#ax.set_xlim(-1,20);\n",
    "#ax.set_ylim(-1,50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(12,13));\n",
    "\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0,0]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0,1]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no Clusters');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1_ref, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1,0]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore Ref');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1_ref, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1,1]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no Clusters Ref');\n",
    "\n",
    "fig.tight_layout();\n",
    "plt.savefig(save_name+\"_PhaseSpaces.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['no_clusters_diff'] = np.asarray(df1.loc[:,'no_clusters'])-np.asarray(df1_ref.loc[:,'no_clusters'])\n",
    "df1 = df1.fillna(0)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters_diff', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0]);\n",
    "ax.invert_yaxis()\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1]);\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters_ref_ratio', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,vmin=0,vmax=0.4,ax=axs[0]);\n",
    "ax.invert_yaxis()\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='similarityScore_ref_ratio', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,vmin=0,vmax=0.4,ax=axs[1]);\n",
    "ax.invert_yaxis()\n",
    "#plt.savefig(outputfolder+\"results_\"+analysis_name+\"_no_clusters_ratio.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = FD_ref.phasespace[['sigma', 'threshold','no_clusters']]\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data);\n",
    "ax.invert_yaxis()\n",
    "#plt.savefig(outputfolder+\"results_\"+analysis_name+\"_noClusters.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = FD_ref.phasespace[['sigma', 'threshold','no_clusters']]\n",
    "df1.loc[:,'no_clusters'] = df1.loc[:,'no_clusters']/np.max(df1.loc[:,'no_clusters']);\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data);\n",
    "ax.invert_yaxis()\n",
    "plt.savefig(outputfolder+\"results_\"+analysis_name+\"_noClusters_norm.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = FD_ref.phasespace[['sigma', 'threshold','similarityScore']]\n",
    "heatmap1_data = pd.pivot_table(df1, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data);\n",
    "ax.invert_yaxis()\n",
    "plt.savefig(outputfolder+\"results_\"+analysis_name+\"_similarityScore.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = FD.phasespace[['sigma', 'threshold','similarityScore_mod']]\n",
    "heatmap1_data = pd.pivot_table(df1, values='similarityScore_mod', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data);\n",
    "ax.invert_yaxis()\n",
    "plt.savefig(outputfolder+\"results_\"+analysis_name+\"_similarityScore_over_noise.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ref = FD_ref.phasespace[['sigma', 'threshold','similarityScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(df1['similarityScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['similarityScore'] = np.asarray(df1['similarityScore'])/np.asarray(df1_ref['similarityScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap1_data = pd.pivot_table(df1, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data);\n",
    "ax.invert_yaxis()\n",
    "#plt.savefig(outputfolder+\"results_\"+analysis_name+\"_similarityScore_relative.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap1_data = pd.pivot_table(df1_ref, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data);\n",
    "ax.invert_yaxis()\n",
    "plt.savefig(outputfolder+\"results_\"+analysis_name+\"_similarityScore_relative.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in np.unique(FD.phasespace['threshold']):\n",
    "    mark = (FD.phasespace['threshold'] == th);\n",
    "    PS_sel = FD.phasespace.loc[mark,:];\n",
    "    idx_max = PS_sel['similarityScore'].idxmax();\n",
    "    PlotScatter(PS_sel.loc[idx_max,'labels'],str(th));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_sel.loc[:,'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
