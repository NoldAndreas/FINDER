{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Definitions import basefolder\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Finder_1d import Finder_1d\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as dist\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from Clustering_CAML import Clustering_CAML\n",
    "import h5py\n",
    "from DbscanLoop import DbscanLoop\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import PlotScatter\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import LoadPoints\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import FilterPoints\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import GetLineOfOptima\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import GetLineOfOptimaUnique\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import GetClusterDistribution\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import GetClusterSizesAlongOptima\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import AnalyseClusterSizes\n",
    "from FigX4_Explore2DOptimizer_withReference_Streamlined_Functions import PlotDistribution\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basefolder = '/Users/andreas/Documents/NoiseRecognizer_WorkingVersion/';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible parameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_TTX = {'mainfolder'    :'ProteinData_ttx_1hr_2/',\\\n",
    "                  'image_filename':'AHA_2_MMStack_Pos0.ome_locs_render_driftcor_filter_render_pix0.02X6f20_X',\\\n",
    "                  'signal_window' :[40000,45000,40000,45000],\\\n",
    "                  'noise_window'  :[50000,60000,40000,50000],\\\n",
    "                  'datascale'     :158,\n",
    "                  'algo'          :'DbscanLoop',\\\n",
    "                  'analysis_name' :'dataWindow_5'};\n",
    "\n",
    "parameters_Mike = {'mainfolder'    :'MikeData/',\\\n",
    "                   'image_filename' :'EGFR-P1-ATTO655_cell_2_MMImages.ome_locs_render_al_linked1sigma_X',\\\n",
    "                   'signal_window'  :[50,60,50,60],\\\n",
    "                   'noise_window'   :[50,100,100,150],\\\n",
    "                   'algo'           :'DbscanLoop',\\\n",
    "                   'analysis_name'  :'dataWindow_1'};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadSaveParameters = 'load';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(loadSaveParameters=='load'):\n",
    "    parameterfile = 'ProteinData_ttx_1hr_2/Analysis_dataWindow_3/dataWindow_3_parameters';\n",
    "#    parameterfile = 'MikeData/Analysis_dataWindow_1/dataWindow_1_parameters';    \n",
    "    \n",
    "    \n",
    "    with open(basefolder+parameterfile+'.json') as f:\n",
    "        parameters = json.load(f);\n",
    "        \n",
    "    if(not ('datascale' in parameters.keys())):\n",
    "        parameters['datascale'] = 1;\n",
    "    \n",
    "elif(loadSaveParameters=='save'):\n",
    "    \n",
    "    parameters                   = parameters_TTX;    \n",
    "    parameters['outputfolder']   = parameters['mainfolder'] + 'Analysis_'+parameters['analysis_name']+'/';    \n",
    "    parameters['save_name']      = parameters['outputfolder']+parameters['analysis_name'];\n",
    "    \n",
    "    parameterfile   = basefolder+parameters['save_name']+'_parameters.json';\n",
    "        \n",
    "    if(os.path.isfile(parameterfile)):\n",
    "        \n",
    "        with open(parameterfile) as f:\n",
    "            parameters_read = json.load(f)\n",
    "        \n",
    "        if(parameters_read == parameters):\n",
    "            print('File exists with equal parameters');\n",
    "        else:\n",
    "            print('File exists with different parameters. File not saved.');\n",
    "    else:\n",
    "        \n",
    "        if not os.path.exists((basefolder+parameters['outputfolder'])):\n",
    "            os.makedirs((basefolder+parameters['outputfolder']))\n",
    "                \n",
    "        with open(parameterfile, 'w') as fp:\n",
    "            json.dump(parameters, fp, indent=4);\n",
    "            \n",
    "        print(\"Parameters saved under \"+parameterfile);\n",
    "else:\n",
    "    print(\"ERROR: Choose load or save\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = basefolder + parameters['save_name'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC_signal = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_signal.txt',datascale=parameters['datascale']);    \n",
    "XC_noise  = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_noise.txt',datascale=parameters['datascale']);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XC_signal = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_signal.txt',datascale=158);    \n",
    "#XC_noise  = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_noise.txt',datascale=158);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "PlotScatter(XC_signal[:,:],ax=axs[0])\n",
    "PlotScatter(XC_noise[:,:],ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC_signal = FilterPoints(XC_signal,parameters['signal_window']);\n",
    "np.savetxt(basefolder+parameters['save_name']+\"_filtered_signal.txt\",XC_signal,fmt=\"%f\\t%f\");   \n",
    "\n",
    "XC_noise  = FilterPoints(XC_noise,parameters['noise_window']);\n",
    "np.savetxt(basefolder+parameters['save_name']+\"_filtered_noise.txt\",XC_noise,fmt=\"%f\\t%f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "PlotScatter(XC_signal,ax=axs[0])\n",
    "PlotScatter(XC_noise,ax=axs[1])\n",
    "#np.savetxt(outputfolder_R+analysis_name+\"_filtered_signal.txt\",XC_signal,fmt=\"%f\\t%f\");    \n",
    "axs[0].set_title('signal,'+str(len(XC_signal))+' points');\n",
    "axs[1].set_title('noise, '+str(len(XC_noise))+' points');\n",
    "for ax in axs:\n",
    "    ax.set_aspect('equal');\n",
    "#axs[1].set_xlim([50,60]);\n",
    "#axs[1].set_ylim([50,60]);\n",
    "plt.savefig(basefolder+parameters['save_name']+\"_localizations_signal_vs_noise.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load or compute clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_ref  = FD_ref.fit(XC_noise,XC_signal,skipSimilarityScore=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadComputeClustering = \"load\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basefolder+parameters['outputfolder']+\"results_\"+parameters['analysis_name'];\n",
    "if(loadComputeClustering == \"compute\"):\n",
    "    FD      = Finder_1d(algo=parameters['algo']);\n",
    "    labels  = FD.fit(XC_signal);    \n",
    "    \n",
    "    with open(filename+'_signal.pickle','wb') as handle:\n",
    "        pickle.dump({'FD':FD}, handle,protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "    \n",
    "    FD_ref      = Finder_1d(algo=parameters['algo']);\n",
    "    labels_ref  = FD_ref.fit(XC_noise,XC_signal,skipSimilarityScore=True );    \n",
    "    \n",
    "    with open(filename+'_noise.pickle','wb') as handle:\n",
    "        pickle.dump({'FD_ref':FD_ref}, handle,protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "    \n",
    "    if(os.path.exists(filename+'.pickle')):\n",
    "        os.remove(filename+'.pickle');\n",
    "    #with open(filename+'.pickle','wb') as handle:\n",
    "    #    pickle.dump({'FD':FD,'FD_ref':FD_ref}, handle,protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "elif(loadComputeClustering == \"load\"):\n",
    "    \n",
    "    if(os.path.exists(filename+'.pickle')):\n",
    "        with open(filename+'.pickle', 'rb') as fr:\n",
    "            FD_load = pickle.load(fr);\n",
    "\n",
    "        FD     = FD_load['FD'];\n",
    "        FD_ref = FD_load['FD_ref'];\n",
    "    else:\n",
    "        with open(filename+'_signal.pickle', 'rb') as fr:\n",
    "            FD_load = pickle.load(fr);\n",
    "        FD     = FD_load['FD'];        \n",
    "\n",
    "        with open(filename+'_noise.pickle', 'rb') as fr:\n",
    "            FD_load = pickle.load(fr);        \n",
    "        FD_ref     = FD_load['FD_ref'];\n",
    "    \n",
    "    print(\"Loaded Clustering results from \"+filename+'.pickle');\n",
    "else:\n",
    "    print(\"ERROR\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1     = FD.phasespace[['sigma', 'threshold','similarityScore','no_clusters']];\n",
    "df1_ref = FD_ref.phasespace[['sigma', 'threshold','similarityScore','no_clusters']];\n",
    "\n",
    "df1['similarityScore_ref']       = df1_ref['similarityScore'];\n",
    "df1['similarityScore_ref_ratio'] = (df1_ref['similarityScore'])/(df1['similarityScore']);\n",
    "\n",
    "df1['no_clusters_ref']       = df1_ref['no_clusters'];\n",
    "df1['no_clusters_ref_ratio'] = (df1_ref['no_clusters'])/(df1['no_clusters']);\n",
    "\n",
    "df_opt_sim = GetLineOfOptima(df1,'similarityScore_ref','similarityScore',15);\n",
    "df_opt_cl  = GetLineOfOptima(df1,'no_clusters_ref','no_clusters',15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## Heatmaps Similiarity Score and Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(12,13));\n",
    "\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0,0]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0,1]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no Clusters');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1_ref, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1,0]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore Ref');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1_ref, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1,1]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no Clusters Ref');\n",
    "\n",
    "fig.tight_layout();\n",
    "plt.savefig(save_name+\"_PhaseSpaces.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Line Of Optima of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = FD.phasespace.loc[2,'labels']\n",
    "aa = np.array([[x,np.sum(a==x)] for x in set(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_th     = GetLineOfOptima(df1,'threshold','similarityScore')\n",
    "df_opt_th_ncl = GetLineOfOptima(df1,'threshold','no_clusters')\n",
    "\n",
    "df_clusterSizes     = GetClusterSizesAlongOptima(FD,df_opt_th);\n",
    "df_clusterSizes_ref = GetClusterSizesAlongOptima(FD_ref,df_opt_th);\n",
    "\n",
    "df_clusterSizes['type'] = 'signal';\n",
    "df_clusterSizes_ref['type'] = 'noise';\n",
    "df_clusterSizes_all = df_clusterSizes.append(df_clusterSizes_ref, ignore_index=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(3,3,figsize=(14,14));\n",
    "\n",
    "ax = axs[0,0];\n",
    "ax.plot(df_opt_th['sigma'],df_opt_th['threshold'],label='similarity Score');\n",
    "sns.scatterplot(x=df_opt_th['sigma'],y=df_opt_th['threshold'],hue=df_opt_th['no_clusters_ref_ratio'],s=100,ax=ax);\n",
    "\n",
    "ax.plot(df_opt_th_ncl['sigma'],df_opt_th_ncl['threshold'],'r',label='no Clusters');\n",
    "sns.scatterplot(x=df_opt_th_ncl['sigma'],y=df_opt_th['threshold'],hue=df_opt_th['no_clusters_ref_ratio'],\\\n",
    "                s=100,ax=ax,palette='Reds');\n",
    "\n",
    "ax.set_xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "ax.set_ylim(np.min(df1['threshold']),np.max(df1['threshold']))\n",
    "\n",
    "ax = axs[0,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore_ref_ratio',ax=ax);\n",
    "sns.lineplot(data=df_opt_th_ncl,x='threshold',y='similarityScore_ref_ratio',ax=ax,color='r');\n",
    "\n",
    "ax = axs[0,2];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters_ref_ratio',ax=ax);\n",
    "sns.lineplot(data=df_opt_th_ncl,x='threshold',y='no_clusters_ref_ratio',ax=ax,color='r');\n",
    "\n",
    "ax = axs[1,0];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['no_clusters']));\n",
    "\n",
    "ax = axs[1,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters_ref',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['no_clusters_ref']));\n",
    "\n",
    "ax = axs[1,2];\n",
    "sns.lineplot(data=df_opt_th,x='no_clusters',y='no_clusters_ref',ax=ax);\n",
    "\n",
    "ax = axs[2,0];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['similarityScore']));\n",
    "\n",
    "ax = axs[2,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore_ref',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['similarityScore_ref']));\n",
    "\n",
    "ax = axs[2,2];\n",
    "sns.lineplot(data=df_opt_th,x='similarityScore',y='similarityScore_ref',ax=ax);\n",
    "\n",
    "plt.savefig(save_name+\"_Analysis_alongLineOfOptima.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotDistribution(df_clusterSizes,df_clusterSizes_ref,save_name+\"_clusterDistribution_alongLineOfOptima_signal.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(15,7));\n",
    "sns.boxplot(data=df_clusterSizes_all,y='clusterSize',x='threshold',hue='type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetOptimalT(df_clusterSizes_all,threshold):\n",
    "    df_signal = df_clusterSizes_all[(df_clusterSizes_all['threshold']==threshold)&\\\n",
    "                    (df_clusterSizes_all['type']=='signal')];\n",
    "    df_noise  = df_clusterSizes_all[(df_clusterSizes_all['threshold']==threshold)&\\\n",
    "                    (df_clusterSizes_all['type']=='noise')];\n",
    "    #ts = np.linspace(10,df_signal['clusterSize'].max(),500);\n",
    "    ts = [];\n",
    "    signal_vs_noise_probability = [];\n",
    "    for t in np.unique(df_signal['clusterSize']):\n",
    "        no_clusters_over_t_noise  = np.sum(df_noise['clusterSize']>t)/len(df_noise['clusterSize']);\n",
    "        no_clusters_over_t_signal = np.sum(df_signal['clusterSize']>t)/len(df_signal['clusterSize']);\n",
    "        if(no_clusters_over_t_signal+no_clusters_over_t_noise > 0):\n",
    "            signal_vs_noise_probability.append(no_clusters_over_t_signal/(no_clusters_over_t_noise+no_clusters_over_t_signal));\n",
    "            ts.append(t);\n",
    "\n",
    "    T = ts[np.argmax(signal_vs_noise_probability)];\n",
    "    #plt.plot(ts,signal_vs_noise_probability);\n",
    "    #print(signal_vs_noise_probability);\n",
    "    #print(ts);    \n",
    "    #print(T);\n",
    "    return T;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetOptimalT(df_clusterSizes_all,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveLabelsSmallerT(labels_input,df,T):\n",
    "    #labels_signal = FD.phasespace.loc[idx_,'labels'];\n",
    "    labels           = labels_input.copy();\n",
    "    labels_to_remove = df.loc[df['clusterSize']<T,'labels'];\n",
    "    for l in np.unique(labels_to_remove):\n",
    "        labels[labels == l] = -1;\n",
    "    return labels;\n",
    "    \n",
    "def FindAndPlot(T,threshold,df_clusterSizes_all,df_opt_th):\n",
    "    #\n",
    "    df_signal = df_clusterSizes_all[(df_clusterSizes_all['threshold']==threshold)*\\\n",
    "                    (df_clusterSizes_all['type']=='signal')];\n",
    "    df_noise  = df_clusterSizes_all[(df_clusterSizes_all['threshold']==threshold)*\\\n",
    "                    (df_clusterSizes_all['type']=='noise')];\n",
    "    \n",
    "    T = GetOptimalT(df_clusterSizes_all,threshold);\n",
    "    #*******************************************************\n",
    "    # Get labels of clusters larger than T\n",
    "    idx_ = int(df_opt_th.loc[df_opt_th['threshold']==threshold,'idx'])\n",
    "    labels_signal = RemoveLabelsSmallerT(FD.phasespace.loc[idx_,'labels'],df_signal,T);\n",
    "    labels_noise  = RemoveLabelsSmallerT(FD_ref.phasespace.loc[idx_,'labels'],df_noise,T);        \n",
    "    #*******************************************************\n",
    "    \n",
    "    fig,axs = plt.subplots(1,2,figsize=(13,8)); \n",
    "    PlotScatter(XC_signal,labels_signal,ax=axs[0])\n",
    "    PlotScatter(XC_noise,labels_noise,ax=axs[1])\n",
    "    axs[0].set_title('signal for clusters with size > '+str(T));\n",
    "    axs[1].set_title('noise for clusters with size > '+str(T));\n",
    "    \n",
    "    #axs[1].set_ylim([57500,62500]);\n",
    "    #axs[1].set_xlim([55000,60000]);\n",
    "    plt.savefig(save_name+\"_OptimalClustering_split_threshold_\"+str(threshold)+\".pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in np.unique(df_opt_th['threshold']):\n",
    "    FindAndPlot(100,th,df_clusterSizes_all,df_opt_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_clusterSizes_all[df_clusterSizes_all['threshold']==11], x=\"clusterSize\",hue='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "def fit_function(k, lamb):\n",
    "    '''poisson function, parameter lamb is the fit parameter'''\n",
    "    return poisson.pmf(k, lamb)\n",
    "    \n",
    "def fit_function_nb(k,n,p):\n",
    "    '''poisson function, parameter lamb is the fit parameter'''\n",
    "    return nbinom.pmf(k, n,p)\n",
    "    \n",
    "    \n",
    "def GetPoissonParameters(data):\n",
    "    # the bins should be of integer width, because poisson is an integer distribution\n",
    "    bins = np.round(np.linspace(0,100,20));#np.arange(100) - 0.5\n",
    "    entries, bin_edges, patches = plt.hist(data, bins=bins, density=True, label='Data');\n",
    "\n",
    "    # calculate bin centres\n",
    "    bin_middles = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    # fit with curve_fit\n",
    "    parameters, cov_matrix = curve_fit(fit_function_nb, bin_middles, entries)\n",
    "    return parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.arange(600)\n",
    "np.sum(x_plot*fit_function_nb(x_plot,r,1-p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max = 200;\n",
    "\n",
    "mark = (df_clusterSizes_all['threshold']==11)*(df_clusterSizes_all['type']=='noise')\n",
    "data = np.array(df_clusterSizes_all.loc[mark,'clusterSize'])\n",
    "\n",
    "data = data[data < data_max]\n",
    "\n",
    "E,V = np.mean(data),np.var(data);\n",
    "r = E**2/(V-E);\n",
    "p = 1-E/V;\n",
    "\n",
    "print('r :',r,' p: ',p);\n",
    "\n",
    "# plot poisson-deviation with fitted parameter\n",
    "bins = np.round(np.linspace(1,data_max,20));#np.arange(100) - 0.5\n",
    "x_plot = np.round(np.linspace(1,data_max,20));#np.arange(100);\n",
    "\n",
    "plt.hist(data, bins=bins, density=True, label='Data');\n",
    "plt.plot(\n",
    "    x_plot,\n",
    "    fit_function_nb(x_plot,r,1-p),\n",
    "    marker='o', linestyle='',\n",
    "    label='Fit result',\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bins should be of integer width, because poisson is an integer distribution\n",
    "bins = np.round(np.linspace(1,100,20));#np.arange(100) - 0.5\n",
    "entries, bin_edges, patches = plt.hist(data, bins=bins, density=True, label='Data');\n",
    "\n",
    "# calculate bin centres\n",
    "bin_middles = np.round(0.5 * (bin_edges[1:] + bin_edges[:-1]))\n",
    "\n",
    "# fit with curve_fit\n",
    "parameters, cov_matrix = curve_fit(fit_function_nb, bin_middles, entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "\n",
    "bins = np.linspace(0,100,20);\n",
    "entries, bin_edges, patches = plt.hist(data, bins=bins, density=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get poisson deviated random numbers\n",
    "#data = np.random.poisson(2, 1000)\n",
    "mark = (df_clusterSizes_all['threshold']==11)*(df_clusterSizes_all['type']=='signal')\n",
    "data = np.array(df_clusterSizes_all.loc[mark,'clusterSize'])\n",
    "parameters = GetPoissonParameters(data)\n",
    "print(parameters)\n",
    "\n",
    "# plot poisson-deviation with fitted parameter\n",
    "x_plot = np.round(np.linspace(1,100,20));#np.arange(100);\n",
    "\n",
    "plt.plot(\n",
    "    x_plot,\n",
    "    fit_function_nb(x_plot,10,0.3),\n",
    "    marker='o', linestyle='',\n",
    "    label='Fit result',\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all.query('clusterSize < 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all.query('clusterSize < 100').groupby(by=['threshold','type']).agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_clusterSizes['type']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_th = AnalyseClusterSizes(df_clusterSizes,df_clusterSizes_ref,save_name+\"_phasespace_alongLineOfOptima.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(12,6))\n",
    "sns.lineplot(data=df_stats_per_th,x='threshold',y='quantile_90',hue='type',ax=axs[0]);\n",
    "sns.lineplot(data=df_stats_per_th,x='threshold',y='n',hue='type',ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in np.unique(df_opt_th['threshold']):\n",
    "    idx_ = int(df_opt_th.loc[df_opt_th['threshold']==th,'idx'])\n",
    "\n",
    "    fig,axs = plt.subplots(1,2,figsize=(13,8)); \n",
    "    PlotScatter(XC_signal,FD.phasespace.loc[idx_,'labels'],ax=axs[0])\n",
    "    PlotScatter(XC_noise,FD_ref.phasespace.loc[idx_,'labels'],ax=axs[1])\n",
    "    axs[0].set_title('signal');\n",
    "    axs[1].set_title('noise');\n",
    "    \n",
    "    axs[1].set_ylim([50,70]);\n",
    "    axs[1].set_xlim([50,70]);\n",
    "    plt.savefig(save_name+\"_OptimalClustering_threshold_\"+str(th)+\".pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse signal vs noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='similarityScore_ref',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'similarityScore_ref'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'similarityScore_ref'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "sns.lineplot(data=df_opt_sim,x='similarityScore_ref',y=\"similarityScore\",color='r',ax=ax)\n",
    "sns.lineplot(data=df_opt_cl,x='similarityScore_ref',y=\"similarityScore\",color='b',ax=ax)\n",
    "ax.set_title('ordered by similarity score');\n",
    "\n",
    "ax      = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "sns.lineplot(data=df_opt_sim,x='no_clusters_ref',y=\"no_clusters\",ax=ax,color='r')\n",
    "sns.lineplot(data=df_opt_cl,x='no_clusters_ref',y=\"no_clusters\",ax=ax,color='b')\n",
    "ax.set_title('ordered by no of clusters');\n",
    "\n",
    "plt.savefig(save_name+\"_phasespace_ordered.pdf\",bbox_inches=\"tight\");\n",
    "#ax.set_xlim(-10,2000);\n",
    "#ax.set_xlim(0,30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='similarityScore_ref_ratio',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'similarityScore_ref_ratio'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'similarityScore_ref_ratio'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "ax.set_xlim(0,1);\n",
    "#ax.set_ylim(-10,4000);\n",
    "\n",
    "ax = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref_ratio',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref_ratio'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref_ratio'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "ax.set_xlim(0,0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "#ax.set_xlim(-10,2000);\n",
    "#ax.set_ylim(-10,4000);\n",
    "\n",
    "ax = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "#ax.set_xlim(-1,20);\n",
    "#ax.set_ylim(-1,50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save for input in R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save phasespace in csv\n",
    "FD_all1 = (FD.phasespace);\n",
    "FD_all1['type'] = 'signal';\n",
    "\n",
    "FD_all2         = (FD_ref.phasespace);\n",
    "FD_all2['type'] = 'noise';\n",
    "\n",
    "(FD_all1.append(FD_all2,ignore_index=True)).to_csv(outputfolder_R+'results_'+analysis_name+'.csv');\n",
    "#(FD.phasespace).to_csv(outputfolder+'results_phasespace'+analysis_name+'.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.zeros((len((FD.phasespace).loc[1,'labels']),len(FD.phasespace)),dtype=np.int32)\n",
    "for i,d in enumerate(FD.phasespace['labels']):\n",
    "    L[:,i] = d;\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_labels_signal.txt\",L,fmt=\"%d\",delimiter='\\t',newline='\\n');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.zeros((len((FD_ref.phasespace).loc[1,'labels']),len(FD_ref.phasespace)),dtype=np.int32)\n",
    "for i,d in enumerate(FD_ref.phasespace['labels']):\n",
    "    L[:,i] = d;\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_labels_noise.txt\",L,fmt=\"%d\",delimiter='\\t',newline='\\n');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(outputfolder_R+analysis_name+\"_filtered_noise.txt\",XC_noise,fmt=\"%f\\t%f\");\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_filtered_signal.txt\",XC_signal,fmt=\"%f\\t%f\");    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_distribution = [];\n",
    "ind = np.zeros((0,),dtype=int);\n",
    "for i,d in enumerate(FD.phasespace['labels']):\n",
    "    d_ = GetClusterDistribution(d);\n",
    "    cls_distribution += (d_);\n",
    "    ind = np.concatenate((ind,i*np.ones_like(d_,dtype=int)))\n",
    "    \n",
    "cls_d = pd.DataFrame();\n",
    "cls_d['size'] = cls_distribution\n",
    "cls_d['index'] = (ind);\n",
    "cls_d.to_csv(outputfolder_R+analysis_name+\"_clusterSizes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(outputfolder_R+analysis_name+\"_clusterSizes.txt\", \"w\") as txt_file:\n",
    "#    for i,d in enumerate(FD.phasespace['labels']):\n",
    "#        d_ = GetClusterDistribution(d);\n",
    "#        txt_file.write(' '.join(str(x) for x in d_)+'\\n') # works with any number of el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a clustering:\n",
    "if(False):\n",
    "    limit_noise_to_signal = 0.4;\n",
    "    \n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['similarityScore_ref_ratio'] < limit_noise_to_signal);\n",
    "    idx_similarityScore  = (df1.loc[mark_,'similarityScore']).idxmax();\n",
    "#    print(df1.loc[idx_similarityScore,:])\n",
    "\n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['no_clusters_ref_ratio'] < limit_noise_to_signal);\n",
    "    idx_no_clusters  = (df1.loc[mark_,'no_clusters']).idxmax();\n",
    "#    print(df1.loc[idx_no_clusters,:])\n",
    "else:\n",
    "    limit_noise_no_cluster = 4;    \n",
    "    limit_noise_similarity = 320;\n",
    "        \n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['similarityScore_ref'] < limit_noise_similarity);\n",
    "    idx_similarityScore  = (df1.loc[mark_,'similarityScore']).idxmax();\n",
    "#    print(df1.loc[idx_similarityScore,:])\n",
    "\n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['no_clusters_ref'] < limit_noise_no_cluster);\n",
    "    idx_no_clusters  = (df1.loc[mark_,'no_clusters']).idxmax();\n",
    "#    print(df1.loc[idx_no_clusters,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(13,13)); \n",
    "PlotScatter(XC_signal,FD.phasespace.loc[idx_similarityScore,'labels'],ax=axs[0,0])\n",
    "PlotScatter(XC_signal,FD.phasespace.loc[idx_no_clusters,'labels'],ax=axs[0,1])\n",
    "\n",
    "PlotScatter(XC_noise,FD_ref.phasespace.loc[idx_similarityScore,'labels'],ax=axs[1,0])\n",
    "PlotScatter(XC_noise,FD_ref.phasespace.loc[idx_no_clusters,'labels'],ax=axs[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: Did we reach a plateau?\n",
    "def Plateau_analysis(x,y):    \n",
    "    x =np.asarray(x);\n",
    "    y =np.asarray(y);    \n",
    "    \n",
    "    y = 0.5*(y[1:]+y[:-1]);\n",
    "    x = 0.5*(x[1:]+x[:-1]);    \n",
    "    \n",
    "    dydx = (y[1:]-y[:-1])/(x[1:]-x[:-1]);\n",
    "#    print(dydx)\n",
    "#    print(y)\n",
    "    plt.plot(x[1:],dydx/y[0],'r');\n",
    "#    plt.plot(x,y,'b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plateau_analysis(df_stats_per_th['threshold'],df_stats_per_th['firstBin'])\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df_stats_per_th['kurtosis'];\n",
    "sns.lineplot(df_stats_per_th['threshold'][1:],np.abs(np.asarray(z[1:])-np.asarray(z[:-1])),label='kurtosis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(np.max(df_clusterSizes['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_clusterSizes.loc[df_clusterSizes['threshold']==11,'clusterSize'],bins=np.linspace(0,100,101)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_opt_sim['sigma'],df_opt_sim['threshold']);\n",
    "sns.scatterplot(x=df_opt_sim['sigma'],y=df_opt_sim['threshold'],hue=df_opt_sim['similarityScore'],s=100);\n",
    "plt.xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "plt.ylim(np.min(df1['threshold']),np.max(df1['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_opt_cl['sigma'],df_opt_cl['threshold']);\n",
    "sns.scatterplot(x=df_opt_cl['sigma'],y=df_opt_cl['threshold'],hue=df_opt_cl['no_clusters'],s=100);\n",
    "plt.xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "plt.ylim(np.min(df1['threshold']),np.max(df1['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['no_clusters_diff'] = np.asarray(df1.loc[:,'no_clusters'])-np.asarray(df1_ref.loc[:,'no_clusters'])\n",
    "df1 = df1.fillna(0)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters_diff', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0]);\n",
    "ax.invert_yaxis()\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1]);\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in np.unique(FD.phasespace['threshold']):\n",
    "    mark = (FD.phasespace['threshold'] == th);\n",
    "    PS_sel = FD.phasespace.loc[mark,:];\n",
    "    idx_max = PS_sel['similarityScore'].idxmax();\n",
    "    PlotScatter(XC_signal,PS_sel.loc[idx_max,'labels']);#,str(th));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_sel.loc[:,'labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the kl divergence\n",
    "def kl_divergence(p, q):\n",
    "    return sum(p[i] * np.log2(p[i]/q[i]) for i in range(len(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCLDist(th):\n",
    "    data = df_clusterSizes[df_clusterSizes['threshold']==th].loc[:,'clusterSize'];\n",
    "    bin_no = (np.histogram(data, bins)[0])/np.sum(np.histogram(data, bins)[0]);\n",
    "    return bin_no;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetCLDist(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,50,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(data, bins,weights=data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence(GetCLDist(3),GetCLDist(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
