#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Oct 20 14:51:43 2020

@author: andreas
"""

import os
import time

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from Clustering_CAML import Clustering_CAML
from Finder import Finder
from scipy.spatial.distance import euclidean
from sklearn.cluster import DBSCAN, OPTICS

# Clustering class


class Clustering:
    def __init__(self, G, basefolder):

        """

        Clusters points generated by `Geometry`

        Parameters
        ----------
        G: Geometry
            The `Geometry` that generates the point to be clustered.
        basefolder: str
            The folder in which the data are saved.
        """
        print(basefolder)
        self.Geometry = G
        self.basefolder = basefolder
        self.min_overlap_per_ref = 0.3

    def fit(self, algo, params=None):
        """

        Parameters
        ----------
        algo: list
            Possible values to  are:
            * 'OPTICS'
            * 'CAML'
            * 'FINDER_1D_loop'
            * 'FINDER_1d'
            * 'FINDER_loop'
            * 'FINDER'
            * 'dbscan'
            *
        params: dict
            The parameters needed for the algorithm.

        Returns
        -------
        results_:
            the labels of the clustering.

        """

        if params is None:
            params = []

        self.algo = algo
        XC = self.Geometry.XC

        result_ = []

        t_start = time.time()

        if algo == "OPTICS":
            params_ = params["OPTICS"]
            threshold = params_["min_samples"]
            xi = params_["xi"]
            eps_max = params_["max_eps"]

            clustering_optics = OPTICS(
                min_samples=threshold,
                xi=xi,
                max_eps=eps_max,
                metric=euclidean,
                cluster_method="xi",
            ).fit(XC)
            # min_cluster_size=.05
            labels = clustering_optics.labels_

        if "CAML" in algo:
            labels = Clustering_CAML(algo, XC, datafolder=self.basefolder)

        elif algo == "FINDER_1D_loop":
            FD = Finder(algo="DbscanLoop", one_two_d="oneD")
            labels = FD.fit(XC)
            result_ = FD.selected_parameters

        elif algo == "FINDER_1D":
            FD = Finder(algo="dbscan", one_two_d="oneD")
            labels = FD.fit(XC)
            result_ = FD.selected_parameters

        elif algo == "FINDER_full_loop":
            FD = Finder(algo="DbscanLoop")
            labels = FD.fit(XC)
            result_ = FD.selected_parameters

        elif algo == "FINDER_full":
            FD = Finder(algo="dbscan")
            labels = FD.fit(XC)
            result_ = FD.selected_parameters

        elif algo == "FINDER_loop":
            FD = Finder(
                algo="DbscanLoop", similarity_score_computation="threshold"
            )
            labels = FD.fit(XC)
            result_ = FD.selected_parameters

            phase_space = FD.phasespace
            phase_space.to_pickle(self.basefolder + "phasespace.pkl")

        elif algo == "FINDER":
            FD = Finder(
                algo="dbscan", similarity_score_computation="threshold"
            )
            labels = FD.fit(XC)
            result_ = FD.selected_parameters

            phase_space = FD.phasespace
            phase_space.to_pickle(self.basefolder + "phasespace.pkl")

        elif algo == "dbscan":
            params_ = params["dbscan"]
            eps = params_["eps"]
            min_samples = params_["min_samples"]
            DB = DBSCAN(eps=eps, min_samples=min_samples).fit(XC)
            labels = DB.labels_

        # clustering_optics = OPTICS(min_samples=threshold, xi=sigma,max_eps=0.3,metric=euclidean,cluster_method='xi').fit(XC) # min_cluster_size=.05

        self.computationTime = time.time() - t_start
        self.labels = labels
        return result_

    def evaluate(self):
        """
        Evaluate the clustering results.
        """

        self.__labelEvaluation()
        self.__clusterEvaluation()
        self.__locEvaluation()
        self.__subClustersPerRefCluster()

    def __labelEvaluation(self):

        """
        Evaluate the labeling performed by the algorithm, comparing it with the ground truth provided
        by the `Geometry` object.

        Returns
        -------
        clusters_correct: np.array

        """

        labels = self.labels
        labels_groundTruth = self.Geometry.labels_groundtruth

        no_clusters = np.max(labels) + 1
        no_clusters_gT = np.max(labels_groundTruth) + 1

        min_overlap_per_ref = self.min_overlap_per_ref
        clusters_correct = -np.ones((no_clusters,), dtype=np.int)

        clusters = [np.where(labels == i)[0] for i in np.arange(no_clusters)]
        clusters_ref = [
            np.where(labels_groundTruth == i)[0]
            for i in np.arange(no_clusters_gT)
        ]

        for i, cl in enumerate(clusters):

            coverage = 0
            idx_chosen = -1

            for ii, cl_ref in enumerate(clusters_ref):
                cl_and_clRef = np.intersect1d(cl, cl_ref)
                clusters_correct[i] = -1
                if len(cl_and_clRef) > min_overlap_per_ref * len(cl_ref):
                    if (len(cl_and_clRef) / len(cl)) > coverage:
                        idx_chosen = ii
                        coverage = len(cl_and_clRef) / len(cl)

            clusters_ref = [
                clusters_ref[i]
                for i in np.arange(len(clusters_ref))
                if (i != idx_chosen)
            ]
            clusters_correct[i] = idx_chosen

        self.clusters_correct = clusters_correct
        return clusters_correct

    def __clusterEvaluation(self):
        """
        Evaluate the performance of the clustering algorithm.

        This is done considering `Clustering.clusters_correct' computed by 'Clustering.__labelEvaluation`.

        Returns
        -------

        cluster_evaluation: dict
            * A dictionary containing:
            * true_positives
            * false_positives
            * false_negatives
            * n_groundtruth
            * false_negative_clusters
            * false_positive_clusters
            * true_positive_clusters
        """

        clusters_correct = self.clusters_correct

        n_groundtruth = np.max((self.Geometry.labels_groundtruth)) + 1
        n_identified = np.max((self.labels)) + 1

        true_positives = np.sum(clusters_correct != -1)
        false_positives = np.sum(clusters_correct == -1)
        false_negatives = n_groundtruth - true_positives

        all_groundtruth = np.arange(n_groundtruth)
        all_identified = np.arange(n_identified)

        false_negative_clusters = np.asarray(
            [a for a in all_groundtruth if (not (a in list(clusters_correct)))]
        )
        false_positive_clusters = np.asarray(
            [i for i in all_identified if (clusters_correct[i] == -1)]
        )
        true_positive_clusters = np.asarray(
            [i for i in all_identified if (clusters_correct[i] != -1)]
        )

        cluster_evaluation = {
            "true_positives": true_positives,
            "false_positives": false_positives,
            "false_negatives": false_negatives,
            "n_groundtruth": n_groundtruth,
            "false_negative_clusters": false_negative_clusters,
            "false_positive_clusters": false_positive_clusters,
            "true_positive_clusters": true_positive_clusters,
        }
        # COMPUTE
        self.cluster_evaluation = cluster_evaluation
        return cluster_evaluation

    def __locEvaluation(self):

        """
        An evaluation performed point by point (instead of comparing clusters).

        Returns
        -------
        dict
            A dict with
            * `true_positives`
            * `false_positives`
            * `false_negatives`
        """

        labels = self.labels
        labels_groundTruth = self.Geometry.labels_groundtruth

        false_positives = np.sum((labels != -1) * (labels_groundTruth == -1))
        false_negatives = np.sum((labels == -1) * (labels_groundTruth != -1))
        true_positives = np.sum((labels != -1) * (labels_groundTruth != -1))

        loc_evaluation = {
            "true_positives": true_positives,
            "false_positives": false_positives,
            "false_negatives": false_negatives,
        }

        self.loc_evaluation = loc_evaluation
        return loc_evaluation

    def __subClustersPerRefCluster(self):

        """

        Returns
        -------
        number_of_subclusters : ndarray
            Entry `i` is how many subclusters reference cluster `i` is divided into
        """
        # Return an array. Entry i is how many subclusters reference cluster
        # i is devided into

        labels_groundTruth = self.Geometry.labels_groundtruth
        labels = self.labels

        n_cl = np.max(labels_groundTruth)

        number_of_subclusters = np.zeros((n_cl + 1,))

        for idx_ref in np.unique(labels_groundTruth):
            if idx_ref == -1:
                continue
            # Get the points
            mark = (labels_groundTruth == idx_ref) * (labels != -1)

            number_of_subclusters[idx_ref] = len(np.unique(labels[mark]))
        self.number_of_subclusters = number_of_subclusters
        return number_of_subclusters

    def plotScatter(self, filename):

        """

        Parameters
        ----------
        filename: str
            Name (and address) of the file to be saved.


        """

        labels = self.labels
        XC = self.Geometry.XC

        # Get correctly detected:
        correct_detected = np.zeros_like(labels)
        for i, cl_ in enumerate(self.clusters_correct):
            if cl_ != -1:  # if not correctly detected
                correct_detected[labels == i] = 1

        fig, ax = plt.subplots()
        mark = labels == -1
        sns.scatterplot(
            x=XC[mark, 0], y=XC[mark, 1], color="grey", s=1, alpha=0.2
        )
        mark = labels >= 0
        sns.scatterplot(
            x=XC[mark, 0],
            y=XC[mark, 1],
            hue=labels[mark],
            palette="bright",
            s=1,
            style=-1 * correct_detected[mark],
            legend=False,
        )
        ax.set_aspect("equal")

        x_0 = 0
        y_0 = np.min(XC[:, 1]) - 50
        ax.plot([x_0, x_0 + 100], [y_0, y_0], "k")
        ax.annotate(
            "$100nm$", (x_0 + 50, y_0 + 10), fontsize="large", ha="center"
        )
        ax.set_aspect(1)
        ax.set_xticks([])
        ax.set_yticks([])
        ax.axis("off")

        plt.savefig(filename)

        # plt.show()
