{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "#from dbscan_inner import dbscan_inner\n",
    "from sklearn.cluster import DBSCAN\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples  = 5;\n",
    "eps     = 0.2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename      = \"../ProteinData_ttx_1hr_2/AHA_2_MMStack_Pos0.ome_locs_render_driftcor_filter_render_pix0.02X6f20\";\n",
    "#filename = \"../MikeData/EGFR-P1-ATTO655_cell_3_MMImages.ome_locs_render\"\n",
    "#filename = \"../MikeData/EGFR-P1-ATTO655_cell_2_MMImages.ome_locs_render_al_linked1sigma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC = np.loadtxt(filename+\".txt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = XC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCluster_Type1(ind):\n",
    "    neighbors_model = NearestNeighbors(\n",
    "        radius=eps, algorithm='auto',\n",
    "        leaf_size=30, metric='euclidean',\n",
    "        metric_params=None, p=None, n_jobs=None)\n",
    "    neighbors_model.fit(X)\n",
    "    # This has worst case O(n^2) memory complexity\n",
    "    neighborhoods = neighbors_model.radius_neighbors(X,return_distance=False)\n",
    "\n",
    "    n_neighbors = np.array([len(neighbors)\n",
    "                            for neighbors in neighborhoods])\n",
    "\n",
    "    # A list of all core samples found.\n",
    "    is_core = np.asarray(n_neighbors >= min_samples,dtype=np.uint8)\n",
    "    \n",
    "    labels = np.full(X.shape[0], -1, dtype=np.intp)\n",
    "    label_num = 0\n",
    "    stack = [];\n",
    "\n",
    "    for i in [ind]:\n",
    "        if labels[i] != -1 or not is_core[i]:\n",
    "            continue\n",
    "\n",
    "        # Depth-first search starting from i, ending at the non-core points.\n",
    "        # This is very similar to the classic algorithm for computing connected\n",
    "        # components, the difference being that we label non-core points as\n",
    "        # part of a cluster (component), but don't expand their neighborhoods.\n",
    "        while True:\n",
    "            if labels[i] == -1:\n",
    "                labels[i] = label_num\n",
    "                if is_core[i]:\n",
    "                    neighb = neighborhoods[i]\n",
    "                    for i in range(neighb.shape[0]):\n",
    "                        v = neighb[i]\n",
    "                        if labels[v] == -1:\n",
    "                            stack.append(v)\n",
    "\n",
    "            if len(stack) == 0:\n",
    "                break\n",
    "            i = stack[-1]\n",
    "            stack = stack[:-1];\n",
    "\n",
    "        label_num += 1\n",
    "    \n",
    "    return labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCluster_Type2(ind):\n",
    "    neighbors_model = NearestNeighbors(\n",
    "        radius=eps, algorithm='auto',\n",
    "        leaf_size=30, metric='euclidean',\n",
    "        metric_params=None, p=None, n_jobs=None)\n",
    "    neighbors_model.fit(X)\n",
    "    # This has worst case O(n^2) memory complexity\n",
    "\n",
    "    #neighborhoods = neighbors_model.radius_neighbors(X,return_distance=False)\n",
    "#    n_neighbors = np.array([len(neighbors) for neighbors in neighborhoods])\n",
    "\n",
    "    \n",
    "    labels    = np.full(X.shape[0], -1, dtype=np.intp)\n",
    "    label_num = 0\n",
    "    stack     = [];\n",
    "    i         = ind;\n",
    "\n",
    "    neighborhood = neighbors_model.radius_neighbors([X[i,:]],return_distance=False)[0]\n",
    "    \n",
    "    if ((len(neighborhood) >= min_samples)):\n",
    "        # Depth-first search starting from i, ending at the non-core points.\n",
    "        # This is very similar to the classic algorithm for computing connected\n",
    "        # components, the difference being that we label non-core points as\n",
    "        # part of a cluster (component), but don't expand their neighborhoods.\n",
    "        while True:\n",
    "            if labels[i] == -1:\n",
    "                labels[i] = label_num\n",
    "                if ((len(neighborhood) >= min_samples)):\n",
    "                    neighb = neighborhood\n",
    "                    for i in range(neighb.shape[0]):\n",
    "                        v = neighb[i]\n",
    "                        if labels[v] == -1:\n",
    "                            stack.append(v)\n",
    "\n",
    "            if len(stack) == 0:\n",
    "                break\n",
    "\n",
    "            #Update\n",
    "            i = stack[-1]        \n",
    "            stack = stack[:-1];\n",
    "            neighborhood = neighbors_model.radius_neighbors([X[i,:]],return_distance=False)[0]\n",
    "\n",
    "    \n",
    "    return labels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2;\n",
    "t1 = time();\n",
    "labels = GetCluster_Type1(ind)\n",
    "print('comp time = '+str(time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 2;\n",
    "t1 = time();\n",
    "labels = GetCluster_Type2(ind)\n",
    "print('comp time = '+str(time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "t1 = time()\n",
    "DB = DBSCAN(eps=eps,min_samples=min_samples).fit(X);\n",
    "labels_DBSCAN = DB.labels_;\n",
    "print('comp time = '+str(time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Is it recognized as noise /signal?\n",
    "if( (labels[ind]>-1) == (labels_DBSCAN[ind] > -1)):\n",
    "    print(\"Correctly identified\");\n",
    "else:\n",
    "    print(\"Not correctly identified as noise / signal\");    \n",
    "    \n",
    "#Is size of the group correct?\n",
    "if( np.sum(labels>-1) == np.sum(labels_DBSCAN == labels_DBSCAN[ind])):\n",
    "    print(\"Size of cluster correctly identified as \"+str(np.sum(labels>-1)));\n",
    "else:\n",
    "    print(\"Size of cluster not correctly identified\");    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
