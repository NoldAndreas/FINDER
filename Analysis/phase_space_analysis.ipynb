{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Geometry_Free import Geometry_Free\n",
    "from Geometry_Grid import Geometry_Grid\n",
    "from Definitions import get_datafolder\n",
    "\n",
    "basefolder = get_datafolder()+'/'\n",
    "\n",
    "def labelEvaluation(labels, labels_groundtruth, min_overlap_per_ref = 0.5 ):\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluate the labeling performed by the algorithm, comparing it with the ground truth provided\n",
    "    by the `Geometry` object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clusters_correct: np.array\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    no_clusters = np.max(labels) + 1\n",
    "    no_clusters_gT = np.max(labels_groundtruth) + 1\n",
    "\n",
    "    clusters_correct = -np.ones((no_clusters,), dtype=np.int)\n",
    "\n",
    "    clusters = [np.where(labels == i)[0] for i in np.arange(no_clusters)]\n",
    "    clusters_ref = [np.where(labels_groundtruth == i)[0] for i in np.arange(no_clusters_gT)]\n",
    "\n",
    "    for i, cl in enumerate(clusters):\n",
    "        coverage = 0\n",
    "        idx_chosen = -1\n",
    "        for ii, cl_ref in enumerate(clusters_ref):\n",
    "            cl_and_clRef = np.intersect1d(cl, cl_ref)\n",
    "            clusters_correct[i] = -1\n",
    "            if len(cl_and_clRef) > min_overlap_per_ref * len(cl_ref):\n",
    "                if (len(cl_and_clRef) / len(cl)) > coverage:\n",
    "                    idx_chosen = ii\n",
    "                    coverage = len(cl_and_clRef) / len(cl)\n",
    "\n",
    "        clusters_ref = [clusters_ref[i] for i in np.arange(len(clusters_ref)) if (i != idx_chosen)]\n",
    "        clusters_correct[i] = idx_chosen\n",
    "\n",
    "    return clusters_correct\n",
    "\n",
    "\n",
    "def clusterEvaluation(labels, labels_groundtruth):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the clustering algorithm.\n",
    "\n",
    "    This is done considering `Clustering.clusters_correct' computed by 'Clustering.__labelEvaluation`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    cluster_evaluation: dict\n",
    "        * A dictionary containing:\n",
    "        * true_positives\n",
    "        * false_positives\n",
    "        * false_negatives\n",
    "        * n_groundtruth\n",
    "        * false_negative_clusters\n",
    "        * false_positive_clusters\n",
    "        * true_positive_clusters\n",
    "    \"\"\"\n",
    "\n",
    "    clusters_correct = labelEvaluation(labels, labels_groundtruth)\n",
    "\n",
    "    n_groundtruth = np.max((labels_groundtruth)) + 1\n",
    "    n_identified = np.max((labels)) + 1\n",
    "\n",
    "    true_positives = np.sum(clusters_correct != -1)\n",
    "    false_positives = np.sum(clusters_correct == -1)\n",
    "    false_negatives = n_groundtruth - true_positives\n",
    "\n",
    "    all_groundtruth = np.arange(n_groundtruth)\n",
    "    all_identified = np.arange(n_identified)\n",
    "\n",
    "    false_negative_clusters = np.asarray([a for a in all_groundtruth if (not (a in list(clusters_correct)))])\n",
    "    false_positive_clusters = np.asarray([i for i in all_identified if (clusters_correct[i] == -1)])\n",
    "    true_positive_clusters = np.asarray([i for i in all_identified if (clusters_correct[i] != -1)])\n",
    "\n",
    "    cluster_evaluation = {\"true_positives\": true_positives,\n",
    "                          \"false_positives\": false_positives,\n",
    "                          \"false_negatives\": false_negatives,\n",
    "                          \"n_groundtruth\": n_groundtruth,\n",
    "                          \"false_negative_clusters\": false_negative_clusters,\n",
    "                          \"false_positive_clusters\": false_positive_clusters,\n",
    "                          \"true_positive_clusters\": true_positive_clusters}\n",
    "    # COMPUTE\n",
    "    return cluster_evaluation\n",
    "\n",
    "def plot_clustering(XC, labels):\n",
    "    plt.figure();\n",
    "    mark = (labels == -1);\n",
    "    sns.scatterplot(x=XC[mark, 0], y=XC[mark, 1], color='grey', s = 5, alpha=1);\n",
    "    mark = (labels >= 0);\n",
    "    sns.scatterplot(x=XC[mark, 0], y=XC[mark, 1], hue=labels[mark], palette='bright', s=5, legend=False);\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    \n",
    "def subClustersPerRefCluster(labels,labels_groundTruth):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    number_of_subclusters : ndarray\n",
    "    Entry `i` is how many subclusters reference cluster `i` is divided into\n",
    "    \"\"\"\n",
    "    # Return an array. Entry i is how many subclusters reference cluster\n",
    "    # i is devided into\n",
    "\n",
    "    n_cl = np.max(labels_groundTruth)\n",
    "    number_of_subclusters = np.zeros((n_cl + 1,))\n",
    "    for idx_ref in np.unique(labels_groundTruth):\n",
    "        if (idx_ref == -1): continue\n",
    "        # Get the points\n",
    "        mark = ((labels_groundTruth == idx_ref) * (labels != -1))\n",
    "        number_of_subclusters[idx_ref] = len(np.unique(labels[mark]))\n",
    "                                                \n",
    "    return number_of_subclusters\n",
    "\n",
    "\n",
    "def locEvaluation(labels,labels_groundTruth):\n",
    "\n",
    "    \"\"\"\n",
    "    An evaluation performed point by point (instead of comparing clusters).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dict with\n",
    "        * `true_positives`\n",
    "        * `false_positives`\n",
    "        * `false_negatives`\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    false_positives = np.sum((labels != -1) * (labels_groundTruth == -1))\n",
    "    false_negatives = np.sum((labels == -1) * (labels_groundTruth != -1))\n",
    "    true_positives = np.sum((labels != -1) * (labels_groundTruth != -1))\n",
    "\n",
    "    loc_evaluation = {\"true_positives\": true_positives,\n",
    "                      \"false_positives\": false_positives,\n",
    "                      \"false_negatives\": false_negatives}\n",
    "\n",
    "    return loc_evaluation\n",
    "\n",
    "def get_labels(sigma_idx,threshold_idx, PS):\n",
    "    \n",
    "    sigmas = np.unique(PS[\"sigma\"])\n",
    "    thresholds = np.unique(PS[\"threshold\"])\n",
    "    rslt_df = PS.loc[(PS['sigma'] == sigmas[sigma_idx]) &\n",
    "              (PS['threshold'] == thresholds[threshold_idx])]\n",
    "    \n",
    "    print (\"sigma = \",sigmas[sigma_idx], \" threshold = \", thresholds[threshold_idx] )\n",
    "\n",
    "    return rslt_df.labels.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----------------------------------\n",
    "# PARAMETERS\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_sigmas = True\n",
    "log_thresholds = False\n",
    "adaptive_sigma_boundaries = False\n",
    "\n",
    "dataset_number = 2\n",
    "noise_ratio = 0.1\n",
    "n_side = 5\n",
    "\n",
    "geometry = \"free\" \n",
    "#geometry = \"grid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----------------\n",
    "# EXECUTION\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_sets = [\"Clusters_Neuron\", #0 \n",
    "             \"Clusters_DNA_1mers\",#1\n",
    "            \"Clusters_DNA_3mers\", #2\n",
    "             \"Clusters_DNA_4mers\"]#3\n",
    "\n",
    "\n",
    "if geometry == \"grid\":\n",
    "    G = Geometry_Grid(basefolder, data_sets[dataset_number],n_side=n_side, noise_ratio = noise_ratio,Delta_ratio=1.5)\n",
    "elif geometry == \"free\":\n",
    "    G = Geometry_Free(basefolder, data_sets[dataset_number], noise_ratio = noise_ratio, n_side = n_side, Delta_ratio = 1)\n",
    "\n",
    "\n",
    "\n",
    "G.GeneratePoints(0)\n",
    "\n",
    "G.labels_groundtruth\n",
    "plot_clustering(G.XC, G.labels_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from finder import Finder\n",
    "\n",
    "XC = G.XC\n",
    "\n",
    "FD = Finder(similarity_score_computation=\"threshold\"\n",
    "               ,minmax_threshold=[5,21]\n",
    "              ,log_sigmas=log_sigmas\n",
    "               ,log_thresholds=log_thresholds\n",
    "               ,adaptive_sigma_boundaries=adaptive_sigma_boundaries\n",
    "              )\n",
    "FD.fit(XC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from AuxiliaryFunctions import *\n",
    "PS = FD.phasespace\n",
    "\n",
    "df_opt_th = GetLineOfOptima(PS, 'threshold', 'similarityScore')\n",
    "\n",
    "line_of_optima = df_opt_th['idx']\n",
    "line_of_optima_sim = np.array(df_opt_th[\"similarityScore\"])\n",
    "\n",
    "opt_normalized = (line_of_optima_sim - line_of_optima_sim.min()) / (line_of_optima_sim.max() - line_of_optima_sim.min())\n",
    "print(opt_normalized)\n",
    "\n",
    "#neuron_path = \"/home/pietro/Documents/Mainz/Project_1_Andreas/Data_Figures/TemplateClusters/NeuronData/dendrite_example_Cell1_GluA2_40I_ROI1_1_MMStack_Pos0.ome_locs_render_driftCorr_filter_render_pix.6fr20_picked2_picked3.txt\"\n",
    "#XC = np.loadtxt(neuron_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "line_of_optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "true_positives = []\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "similarity = []\n",
    "subclusters_division = []\n",
    "no_clusters = []\n",
    "\n",
    "ground_truth = True\n",
    "\n",
    "for i, row in PS.iterrows():\n",
    "    #print(row[\"sigma\"], row[\"threshold\"],row[\"similarityScore\"])\n",
    "    labels = row[\"labels\"]\n",
    "    \n",
    "    if ground_truth: \n",
    "        values = locEvaluation(labels, G.labels_groundtruth)\n",
    "        n_subcl= subClustersPerRefCluster(labels, G.labels_groundtruth)\n",
    "        #print(n_subcl)\n",
    "        occur = np.zeros(11)\n",
    "        for i in range(10):\n",
    "            occur[i] = np.sum(n_subcl == i)\n",
    "        occur[10] = np.sum(n_subcl >= 10)\n",
    "        true_positives.append(values[\"true_positives\"])\n",
    "        false_positives.append(values[\"false_positives\"])\n",
    "        false_negatives.append(values[\"false_negatives\"])\n",
    "        subclusters_division.append(occur)\n",
    "    similarity.append(row[\"similarityScore\"])\n",
    "    no_clusters.append(row[\"no_clusters\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tp_matr = np.round(np.flipud(np.array(true_positives).reshape(15,-1).T),2)\n",
    "fp_matr = np.round(np.flipud(np.array(false_positives).reshape(15,-1).T),2)\n",
    "fn_matr = np.round(np.flipud(np.array(false_negatives).reshape(15,-1).T),2)\n",
    "sim_matr = np.round(np.flipud(np.array(similarity).reshape(15,-1).T),2)\n",
    "n_cl_matr = np.round(np.flipud(np.array(no_clusters).reshape(15,-1).T),2)\n",
    "\n",
    "\n",
    "F1_matr = tp_matr/(tp_matr + 0.5*(fp_matr + fn_matr))\n",
    "\n",
    "        \n",
    "cl_2_matr = np.flipud((np.array(subclusters_division)[:,2]).reshape(15,-1).T)\n",
    "cl_3_matr = np.flipud(np.array(subclusters_division)[:,3].reshape(15,-1).T)\n",
    "cl_4_matr = np.flipud(np.array(subclusters_division)[:,4].reshape(15,-1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.array(subclusters_division).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigmas = np.unique(PS[\"sigma\"])\n",
    "thresholds = np.unique(PS[\"threshold\"])\n",
    "\n",
    "max_list = []\n",
    "\n",
    "for t,s in enumerate(sim_matr.argmax(1)):\n",
    "    max_list.append(s)\n",
    "    print(sim_matr[t,s], np.flipud(thresholds)[t], sigmas[s])\n",
    "    \n",
    "max_list = max_list[::-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=1,ncols=3,figsize=(15,5))\n",
    "sns.heatmap(tp_matr*100/len(XC),xticklabels=np.round(sigmas,2),yticklabels=np.flipud(np.round(thresholds)),annot=True,ax=axs[0],cbar=False,cmap='Reds');\n",
    "sns.heatmap(fp_matr*100/len(XC),xticklabels=np.round(sigmas,2),yticklabels=np.flipud(np.round(thresholds)),annot=True,ax=axs[1],cbar=False,cmap='Reds');\n",
    "sns.heatmap(sim_matr,xticklabels=np.round(sigmas,2),yticklabels=np.flipud(np.round(thresholds)),annot=True,ax=axs[2],cbar=False,cmap='Reds');\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "\n",
    "axs[0].set_title(\"true positives\")\n",
    "axs[1].set_title(\"false positives\")\n",
    "axs[2].set_title(\"Similarity Score\")\n",
    "\n",
    "for l in range(3):\n",
    "    for i, j in enumerate(max_list[::-1]):\n",
    "        axs[l].add_patch(Rectangle((j, i), 1, 1, fill=False, edgecolor='blue', lw=3)) \n",
    "\n",
    "        \n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig,axs = plt.subplots(nrows=1,ncols=3,figsize=(15,5))\n",
    "sns.heatmap(cl_2_matr,xticklabels=np.round(sigmas,2),yticklabels=np.flipud(np.round(thresholds)),annot=True,ax=axs[0],cbar=False,cmap='Blues');\n",
    "sns.heatmap(cl_3_matr,xticklabels=np.round(sigmas,2),yticklabels=np.flipud(np.round(thresholds)),annot=True,ax=axs[1],cbar=False,cmap='Blues');\n",
    "sns.heatmap(cl_4_matr,xticklabels=np.round(sigmas,2),yticklabels=np.flipud(np.round(thresholds)),annot=True,ax=axs[2],cbar=False,cmap='Blues');\n",
    "from matplotlib.patches import Rectangle\n",
    "axs[0].set_title(\"2 Subclusters\")\n",
    "axs[1].set_title(\"3 Subclusters\")\n",
    "axs[2].set_title(\"4 Subclusters\")\n",
    "\n",
    "for l in range(3):\n",
    "    for i, j in enumerate(max_list[::-1]):\n",
    "        axs[l].add_patch(Rectangle((j, i), 1, 1, fill=False, edgecolor='blue', lw=3))\n",
    "print()       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
    "\n",
    "sns.heatmap(F1_matr,xticklabels=np.round(sigmas,2),yticklabels=np.flipud(np.round(thresholds)),annot=True,ax = axs, cbar=False,cmap='Reds');\n",
    "for l in range(3):\n",
    "    for i, j in enumerate(max_list[::-1]):\n",
    "        axs.add_patch(Rectangle((j, i), 1, 1, fill=False, edgecolor='blue', lw=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt_sim = []\n",
    "opt_n_cl = []\n",
    "for i, j in enumerate(max_list[::-1]):\n",
    "    #print(thresholds[::-1][i], sigmas[j], sim_matr[i,j])\n",
    "    opt_sim.append(sim_matr[i,j])\n",
    "    opt_n_cl.append(n_cl_matr[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(thresholds, opt_sim[::-1])\n",
    "plt.plot(thresholds, FD.sim_score_opt)\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "plt.legend([\"Sim_threshold\", \"Sim_diag\"])\n",
    "plt.show()\n",
    "plt.plot(thresholds, opt_n_cl[::-1], '*')\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"Number of clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt_sim = []\n",
    "opt_n_cl = []\n",
    "\n",
    "for i, j in enumerate(max_list[::-1]):\n",
    "    #print(thresholds[::-1][i], sigmas[j], sim_matr[i,j])\n",
    "    opt_sim.append(sim_matr[i,j])\n",
    "    opt_n_cl.append(n_cl_matr[i,j])\n",
    "\n",
    "opt_sim = np.array(opt_sim)\n",
    "opt_n_cl = np.array(opt_n_cl)\n",
    "\n",
    "\n",
    "plt.plot(thresholds,(opt_sim[::-1] - opt_sim.min())/(opt_sim.max() - opt_sim.min()) )\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(thresholds, (opt_n_cl[::-1] - opt_n_cl.min())/(opt_n_cl.max() - opt_n_cl.min()) , '*')\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"Number of clusters\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "#a = (opt_n_cl[::-1] - opt_n_cl.min())/(opt_n_cl.max() - opt_n_cl.min()) \n",
    "a = (opt_sim[::-1] - opt_sim.min())/(opt_sim.max() - opt_sim.min())\n",
    "\n",
    "ind = np.where(a<0.5)\n",
    "\n",
    "\n",
    "#s = 6\n",
    "#t = 7\n",
    "t = ind[0][0]\n",
    "\n",
    "s = max_list[t]\n",
    "\n",
    "labels = get_labels(s,t,PS)\n",
    "\n",
    "plot_clustering(G.XC, labels)\n",
    "cc = subClustersPerRefCluster(labels, G.labels_groundtruth)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(data=cc, discrete=True, shrink=0.8)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "ax.set_ylim(0, 25)\n",
    "ax.set_xlim(0, 11)\n",
    "ax.set_xticks(np.arange(10 + 1))\n",
    "xlabs = [str(i) for i in np.arange(10 + 1)]\n",
    "xlabs[-1] = \">= 10\"\n",
    "ax.set_xticklabels(xlabs)\n",
    "ax.set_xlabel('Detected subclusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from Finder import Finder_1d_old\n",
    "\n",
    "# FD_old = Finder_1d_old()\n",
    "# AA = FD_old.fit(XC)\n",
    "\n",
    "# plot_clustering(G.XC, AA)\n",
    "# cc = subClustersPerRefCluster(AA, G.labels_groundtruth)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# sns.histplot(data=cc, discrete=True, shrink=0.8)\n",
    "# ax.set_xlabel(\"\")\n",
    "# ax.set_ylabel(\"\")\n",
    "# ax.set_yticks([])\n",
    "# ax.set_xticks([])\n",
    "# ax.set_ylim(0, 25)\n",
    "# ax.set_xlim(0, 11)\n",
    "# ax.set_xticks(np.arange(10 + 1))\n",
    "# xlabs = [str(i) for i in np.arange(10 + 1)]\n",
    "# xlabs[-1] = \">= 10\"\n",
    "# ax.set_xticklabels(xlabs)\n",
    "# ax.set_xlabel('Detected subclusters')\n",
    "# plt.show()\n",
    "\n",
    "# for i in FD_old.phasespace:\n",
    "#     print(i[\"sigma\"])\n",
    "# sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% raw\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
