{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as dist\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from Clustering_CAML import Clustering_CAML\n",
    "import h5py\n",
    "from DbscanLoop import DbscanLoop\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "import json\n",
    "from numpy.fft import fft2, fftshift, ifft2\n",
    "import os.path\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import signal\n",
    "from ProgressBar import printProgressBar\n",
    "\n",
    "from SimilarityScore import getSimilarityScore,getClusterSizesAll,getSimilarityScore_ij\n",
    "\n",
    "from FigY_Functions import PlotScatter,LoadPoints\n",
    "from FigY_Functions import FilterPoints\n",
    "from FigY_Functions import GetLineOfOptima,GetLineOfOptimaUnique\n",
    "from FigY_Functions import GetClusterDistribution,GetClusterSizesAlongOptima\n",
    "from FigY_Functions import PlotDistribution,AnalyseClusterSizes\n",
    "from FigY_Functions import GetDensity,GetOverlay,GetOptimalT\n",
    "from FigY_Functions import DefineCleanedLabels\n",
    "\n",
    "from ClustersInOutCell import ClustersInOutCell\n",
    "from Finder import Finder\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('font',**{'family':'sans-serif','serif':['Arial']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible parameter sets\n",
    "parameters_TTX = {'mainfolder'    :'ProteinData_ttx_1hr_2/',\\\n",
    "                  'image_filename':'AHA_2_MMStack_Pos0.ome_locs_render_driftcor_filter_render_pix0.02X6f20_X',\\\n",
    "                  'incell_window' :[40000,45000,40000,45000],\\\n",
    "                  'noise_window'  :[50000,60000,40000,50000],\\\n",
    "                  'datascale'     :158,\n",
    "                  'algo'          :'DbscanLoop',\\\n",
    "                  'analysis_name' :'dataWindow_5'};\n",
    "\n",
    "parameters_Mike = {'mainfolder'    :'MikeData/',\\\n",
    "                   'image_filename' :'EGFR-P1-ATTO655_cell_2_MMImages.ome_locs_render_al_linked1sigma_X',\\\n",
    "                   'incell_window'  :[50,60,50,60],\\\n",
    "                   'noise_window'   :[50,100,100,150],\\\n",
    "                   'algo'           :'DbscanLoop',\\\n",
    "                   'analysis_name'  :'dataWindow_1'};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "basefolder = '../../OtherData/';\n",
    "\n",
    "#    parameterfile = 'ProteinData_ttx_1hr_2/Analysis_dataWindow_3/dataWindow_3_parameters';\n",
    "#    parameterfile = 'ProteinData_ttx_1hr_2/Analysis_dataWindow_7/dataWindow_7_parameters'; \n",
    "#parameterfile = 'AnalysisDataOrganized/TTX_control_1/Output/2022_01_07__14_30_09/parameters_window'\n",
    "parameterfile = 'MikeData/Analysis_dataWindow_1/dataWindow_1_parameters';    \n",
    "\n",
    "loadSaveParameters = 'load';\n",
    "loadComputeClustering = \"load\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(loadSaveParameters=='load'):\n",
    "   # parameterfile = 'MikeData/Analysis_dataWindow_1/dataWindow_1_parameters';    \n",
    "        \n",
    "    with open(basefolder+parameterfile+'.json') as f:\n",
    "        parameters = json.load(f);\n",
    "        \n",
    "    if(not ('datascale' in parameters.keys())):\n",
    "        parameters['datascale'] = 1;\n",
    "    \n",
    "elif(loadSaveParameters=='save'):\n",
    "    \n",
    "    parameters                   = parameters_TTX;    \n",
    "        \n",
    "    if(os.path.isfile(parameterfile)):\n",
    "        \n",
    "        with open(parameterfile) as f:\n",
    "            parameters_read = json.load(f)\n",
    "        \n",
    "        if(parameters_read == parameters):\n",
    "            print('File exists with equal parameters');\n",
    "        else:\n",
    "            print('File exists with different parameters. File not saved.');\n",
    "    else:\n",
    "        \n",
    "        if not os.path.exists((basefolder+parameters['outputfolder'])):\n",
    "            os.makedirs((basefolder+parameters['outputfolder']))\n",
    "                \n",
    "        with open(parameterfile, 'w') as fp:\n",
    "            json.dump(parameters, fp, indent=4);\n",
    "            \n",
    "        print(\"Parameters saved under \"+parameterfile);\n",
    "else:\n",
    "    print(\"ERROR: Choose load or save\");\n",
    "    \n",
    "parameters['outputfolder']   = parameters['mainfolder'] + 'Analysis_'+parameters['analysis_name']+'/';    \n",
    "parameters['save_name']      = parameters['outputfolder']+parameters['analysis_name'];    \n",
    "parameterfile                = basefolder+parameters['save_name']+'_parameters.json';\n",
    "save_name                    = basefolder + parameters['save_name'];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.isfile(basefolder+parameters['save_name']+\"_filtered_incell.txt\")):\n",
    "    XC_incell  = LoadPoints(basefolder+parameters['save_name']+\"_filtered_incell.txt\",datascale=parameters['datascale']);    \n",
    "    XC_outcell = LoadPoints(basefolder+parameters['save_name']+\"_filtered_outcell.txt\",datascale=parameters['datascale']);        \n",
    "else:\n",
    "    XC_incell  = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_incell.txt',datascale=parameters['datascale']);    \n",
    "    XC_outcell = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_outcell.txt',datascale=parameters['datascale']);    \n",
    "    \n",
    "    XC_incell   = FilterPoints(XC_incell,parameters['incell_window']);\n",
    "    XC_outcell  = FilterPoints(XC_outcell,parameters['outcell_window']);\n",
    "    \n",
    "    XC_outcell_overlay = GetOverlay(XC_incell,XC_outcell);\n",
    "    \n",
    "    np.savetxt(basefolder+parameters['save_name']+\"_filtered_incell.txt\",XC_incell,fmt=\"%f\\t%f\");   \n",
    "    np.savetxt(basefolder+parameters['save_name']+\"_filtered_outcell.txt\",XC_outcell,fmt=\"%f\\t%f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XC_incell = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_incell.txt',datascale=158);    \n",
    "#XC_outcell  = LoadPoints(basefolder+parameters['mainfolder']+parameters['image_filename']+'_outcell.txt',datascale=158);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "#PlotScatter(XC_incell[:,:],ax=axs[0])\n",
    "#PlotScatter(XC_outcell[:,:],ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = basefolder+parameters['outputfolder']+\"results_\"+parameters['analysis_name'];\n",
    "if(loadComputeClustering == \"compute\"):\n",
    "    FD      = Finder(algo=parameters['algo']);\n",
    "    labels  = FD.fit(XC_incell);    \n",
    "    \n",
    "    with open(filename+'_incell.pickle','wb') as handle:\n",
    "        pickle.dump({'FD':FD}, handle,protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "    \n",
    "    FD_ref      = Finder(algo=parameters['algo']);\n",
    "    labels_ref  = FD_ref.fit(XC_outcell,XC_incell);    \n",
    "    \n",
    "    with open(filename+'_outcell.pickle','wb') as handle:\n",
    "        pickle.dump({'FD_ref':FD_ref}, handle,protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "    \n",
    "    if(os.path.exists(filename+'.pickle')):\n",
    "        os.remove(filename+'.pickle');\n",
    "    #with open(filename+'.pickle','wb') as handle:\n",
    "    #    pickle.dump({'FD':FD,'FD_ref':FD_ref}, handle,protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "elif(loadComputeClustering == \"load\"):\n",
    "    \n",
    "    if(os.path.exists(filename+'.pickle')):\n",
    "        with open(filename+'.pickle', 'rb') as fr:\n",
    "            FD_load = pickle.load(fr);\n",
    "\n",
    "        FD     = FD_load['FD'];\n",
    "        FD_ref = FD_load['FD_ref'];\n",
    "        print(\"Loaded Clustering results from \"+filename+'.pickle');\n",
    "    else:\n",
    "        with open(filename+'_incell.pickle', 'rb') as fr:\n",
    "            FD_load = pickle.load(fr);\n",
    "        FD     = FD_load['FD'];        \n",
    "        print(\"Loaded Clustering results from \"+filename+'_incell.pickle');\n",
    "\n",
    "        with open(filename+'_outcell.pickle', 'rb') as fr:\n",
    "            FD_load = pickle.load(fr);        \n",
    "        FD_ref     = FD_load['FD_ref'];\n",
    "        print(\"Loaded Clustering results from \"+filename+'_outcell.pickle');        \n",
    "        \n",
    "else:\n",
    "    print(\"ERROR\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phasespace_all = FD.phasespace;\n",
    "phasespace_all['labels_ref'] = FD_ref.phasespace['labels']\n",
    "phasespace_all['no_clusters_ref'] = FD_ref.phasespace['no_clusters'];\n",
    "phasespace_all['time_ref'] = FD_ref.phasespace['time'];\n",
    "\n",
    "#Define abbreviated phasespace \n",
    "\n",
    "df1     = FD.phasespace[['sigma', 'threshold','similarityScore','no_clusters']];\n",
    "df1_ref = FD_ref.phasespace[['sigma', 'threshold','similarityScore','no_clusters']];\n",
    "\n",
    "df1['similarityScore_ref']       = df1_ref['similarityScore'];\n",
    "df1['similarityScore_ref_ratio'] = (df1_ref['similarityScore'])/(df1['similarityScore']);\n",
    "\n",
    "df1['no_clusters_ref']       = df1_ref['no_clusters'];\n",
    "df1['no_clusters_ref_ratio'] = (df1_ref['no_clusters'])/(df1['no_clusters']);\n",
    "\n",
    "#Assemble all cluster sizes\n",
    "df_clusterSizes     = FD.clusterInfo;#GetClusterSizesAll(FD);\n",
    "df_clusterSizes_ref = FD_ref.clusterInfo;#'GetClusterSizesAll(FD_ref);\n",
    "\n",
    "df_clusterSizes['type'] = 'incell';\n",
    "df_clusterSizes_ref['type'] = 'outcell';\n",
    "df_clusterSizes_all = df_clusterSizes.append(df_clusterSizes_ref, ignore_index=True);\n",
    "\n",
    "#Analyse line of optimal sigmas\n",
    "#df_opt_sim = GetLineOfOptima(df1,'similarityScore_ref','similarityScore',15);\n",
    "#df_opt_cl  = GetLineOfOptima(df1,'no_clusters_ref','no_clusters',15);\n",
    "\n",
    "df_opt_th     = GetLineOfOptima(df1,'threshold','similarityScore')\n",
    "df_opt_th_ncl = GetLineOfOptima(df1,'threshold','no_clusters')\n",
    "\n",
    "df_clusterSizes_opt     = GetClusterSizesAlongOptima(FD,df_opt_th);\n",
    "df_clusterSizes_ref_opt = GetClusterSizesAlongOptima(FD_ref,df_opt_th);\n",
    "\n",
    "df_clusterSizes_opt['type'] = 'incell';\n",
    "df_clusterSizes_ref_opt['type'] = 'outcell';\n",
    "df_clusterSizes_all_opt = df_clusterSizes_opt.append(df_clusterSizes_ref_opt, ignore_index=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot overview Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Overview\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "PlotScatter(XC_incell,ax=axs[0])\n",
    "PlotScatter(XC_outcell,ax=axs[1])\n",
    "#np.savetxt(outputfolder_R+analysis_name+\"_filtered_incell.txt\",XC_incell,fmt=\"%f\\t%f\");    \n",
    "axs[0].set_title('in cell,'+str(len(XC_incell))+' points');\n",
    "#axs[0].set_xlim(150,158);\n",
    "#axs[0].set_ylim(140,147);\n",
    "\n",
    "axs[1].set_title('out cell, '+str(len(XC_outcell))+' points');\n",
    "for ax in axs:\n",
    "    ax.set_aspect('equal');\n",
    "\n",
    "if(True): \n",
    "    axs[0].axis('off');\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    axs[0].set_title('Inside of cell');\n",
    "    axs[1].set_title('Reference -- Outside of cell');\n",
    "#axs[1].set_xlim([50,60]);\n",
    "#axs[1].set_ylim([50,60]);\n",
    "\n",
    "plt.savefig(basefolder+parameters['save_name']+\"_localizations_incell_vs_outcell.pdf\",bbox_inches=\"tight\");\n",
    "plt.savefig(basefolder+parameters['save_name']+\"_localizations_incell_vs_outcell.png\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps Similiarity Score and Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(12,13));\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0,0]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0,1]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no Clusters');\n",
    "\n",
    "if(df1_ref['similarityScore'].isnull().sum() == 0):\n",
    "    heatmap1_data = pd.pivot_table(df1_ref, values='similarityScore', \n",
    "                         index=['threshold'], \n",
    "                         columns='sigma')\n",
    "    ax = sns.heatmap(heatmap1_data,ax=axs[1,0]);\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title('similarityScore Ref');\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1_ref, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1,1]);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no Clusters Ref');\n",
    "\n",
    "fig.tight_layout();\n",
    "plt.savefig(save_name+\"_PhaseSpaces.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Line Of Optima of incell signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(3,3,figsize=(14,14));\n",
    "\n",
    "ax = axs[0,0];\n",
    "ax.plot(df_opt_th['sigma'],df_opt_th['threshold'],label='similarity Score');\n",
    "sns.scatterplot(x=df_opt_th['sigma'],y=df_opt_th['threshold'],hue=df_opt_th['no_clusters_ref_ratio'],s=100,ax=ax);\n",
    "\n",
    "ax.plot(df_opt_th_ncl['sigma'],df_opt_th_ncl['threshold'],'r',label='no Clusters');\n",
    "sns.scatterplot(x=df_opt_th_ncl['sigma'],y=df_opt_th['threshold'],hue=df_opt_th['no_clusters_ref_ratio'],\\\n",
    "                s=100,ax=ax,palette='Reds');\n",
    "\n",
    "ax.set_xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "ax.set_ylim(np.min(df1['threshold']),np.max(df1['threshold']))\n",
    "\n",
    "ax = axs[0,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore_ref_ratio',ax=ax);\n",
    "sns.lineplot(data=df_opt_th_ncl,x='threshold',y='similarityScore_ref_ratio',ax=ax,color='r');\n",
    "\n",
    "ax = axs[0,2];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters_ref_ratio',ax=ax);\n",
    "sns.lineplot(data=df_opt_th_ncl,x='threshold',y='no_clusters_ref_ratio',ax=ax,color='r');\n",
    "\n",
    "ax = axs[1,0];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['no_clusters']));\n",
    "\n",
    "ax = axs[1,1];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='no_clusters_ref',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['no_clusters_ref']));\n",
    "\n",
    "ax = axs[1,2];\n",
    "sns.lineplot(data=df_opt_th,x='no_clusters',y='no_clusters_ref',ax=ax);\n",
    "\n",
    "ax = axs[2,0];\n",
    "sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore',ax=ax);\n",
    "ax.set_ylim(0,1.1*np.max(df_opt_th['similarityScore']));\n",
    "\n",
    "if(df_opt_th['similarityScore_ref'].isnull().sum()==0):\n",
    "    ax = axs[2,1];\n",
    "    sns.lineplot(data=df_opt_th,x='threshold',y='similarityScore_ref',ax=ax);\n",
    "    ax.set_ylim(0,1.1*np.max(df_opt_th['similarityScore_ref']));\n",
    "\n",
    "    ax = axs[2,2];\n",
    "    sns.lineplot(data=df_opt_th,x='similarityScore',y='similarityScore_ref',ax=ax);\n",
    "\n",
    "plt.savefig(save_name+\"_Analysis_alongLineOfOptima.pdf\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotDistribution(df_clusterSizes,df_clusterSizes_ref,save_name+\"_clusterDistribution_alongLineOfOptima_incell.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(15,7));\n",
    "sns.boxplot(data=df_clusterSizes_all,y='clusterSize',x='threshold',hue='type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative analysis of along line of optima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incell = df_clusterSizes_all[(df_clusterSizes_all['type']=='incell')];\n",
    "df_outcell  = df_clusterSizes_all[(df_clusterSizes_all['type']=='outcell')];\n",
    "T_,s_vs_n_,nocl_incell_,nocl_outcell_ = GetOptimalT(df_incell,df_outcell,'similarityScore');\n",
    "T_,s_vs_n_,nocl_incell_,nocl_outcell_ = GetOptimalT(df_incell,df_outcell,'clusterSize');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phasespace_all_aboveT = DefineCleanedLabels(df_clusterSizes_all,phasespace_all,criterion='similarityScore',bestRequiredRate=1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_choose  = np.argmax(phasespace_all_aboveT['no_clusters']);\n",
    "ps_choose = phasespace_all_aboveT.loc[i_choose,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusterInfo        = getClusterSizesAll(XC_incell,phasespace_all);\n",
    "clusterInfo_aboveT = getClusterSizesAll(XC_incell,phasespace_all_aboveT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_similarityScore,similarityScore      = getSimilarityScore(XC_incell,phasespace_all_aboveT,clusterInfo_aboveT);\n",
    "phasespace_all_aboveT['similarityScore'] = similarityScore;\n",
    "clusterInfo_aboveT['similarityScore']    = cli_similarityScore;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_th_aboveT     = GetLineOfOptima(phasespace_all_aboveT[['sigma', 'threshold','similarityScore','no_clusters']],'threshold','similarityScore');\n",
    "df_opt_th_aboveT_ncl = GetLineOfOptima(phasespace_all_aboveT[['sigma', 'threshold','similarityScore','no_clusters']],'threshold','no_clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2dS = np.random.rand(200,200);\n",
    "hist2dS = gaussian_filter(hist2dS, sigma=10); \n",
    "\n",
    "#hist2dS = np.histogram2d(XC_incell[:,0],XC_incell[:,1],bins=200)[0];\n",
    "hist2dS = np.histogram2d(XC_outcell[:,0],XC_outcell[:,1],bins=200)[0];\n",
    "hist2dS[hist2dS>1] = 1;\n",
    "#hist2dS = gaussian_filter(hist2dS, sigma=10)\n",
    "#hist2dS = hist2dS.T;\n",
    "\n",
    "plt.imshow(hist2dS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = signal.correlate2d(hist2dS, hist2dS,boundary='wrap', mode='full')# boundary='symm'\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(figsize=(13, 3), ncols=3)\n",
    "\n",
    "pos = ax1.imshow(corr,vmin=0);\n",
    "fig.colorbar(pos,ax=ax1)\n",
    "\n",
    "ax2.plot(np.sum(corr,axis=0));\n",
    "ax3.plot(np.sum(corr,axis=1));\n",
    "\n",
    "ax2.set_ylim([0,220000]);\n",
    "ax3.set_ylim([0,220000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = fft2(hist2dS) \n",
    "F = fftshift(F)\n",
    "fft_hust2dS = np.abs(F) \n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(figsize=(13, 3), ncols=3)\n",
    "\n",
    "ax1.imshow(fft_hust2dS);\n",
    "#fft_hust2dS = np.abs(np.fft.fft2(hist2dS));\n",
    "#plt.imshow(abs(fft_hust2dS));\n",
    "ax2.plot(np.sum(fft_hust2dS,axis=0))\n",
    "ax3.plot(np.sum(fft_hust2dS,axis=1))\n",
    "\n",
    "ax2.set_ylim([0,15000]);\n",
    "ax3.set_ylim([0,15000]);\n",
    "\n",
    "#hist2dS = np.histogram2d(XC_outcell[:,0],XC_outcell[:,1],bins=100);\n",
    "#plt.imshow(np.imag(np.fft.fft2(hist2dS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hW, hH = 100,50\n",
    "hFreq = 5\n",
    "\n",
    "# Mesh on the square [0,1)x[0,1)\n",
    "x = np.linspace( 0, 2*hW/(2*hW +1), 2*hW+1)     # columns (Width)\n",
    "y = np.linspace( 0, 2*hH/(2*hH +1), 2*hH+1)     # rows (Height)\n",
    "\n",
    "[X,Y] = np.meshgrid(x,y)\n",
    "A = np.sin(hFreq*2*np.pi*X)\n",
    "\n",
    "plt.imshow(A, cmap = 'gray');\n",
    "H,W = np.shape(A)\n",
    "\n",
    "F = fft2(A)/(W*H)                          \n",
    "F = fftshift(F)\n",
    "P = np.abs(F)                            \n",
    "#plt.imshow(P);\n",
    "\n",
    "# ***** PLot\n",
    "corr = signal.correlate2d(A,A,boundary='wrap', mode='full')# boundary='symm'\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(figsize=(13, 3), ncols=3)\n",
    "\n",
    "pos = ax1.imshow(corr,vmin=0);\n",
    "fig.colorbar(pos,ax=ax1)\n",
    "\n",
    "ax2.plot(np.sum(corr,axis=0));\n",
    "ax3.plot(np.sum(corr,axis=1));\n",
    "\n",
    "#ax2.set_ylim([0,220000]);\n",
    "#ax3.set_ylim([0,220000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results of postprocessing / Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(14,7));\n",
    "PlotScatter(XC_incell,ps_choose['labels'],axs[0]);\n",
    "PlotScatter(XC_outcell,ps_choose['labels_ref'],axs[1]);\n",
    "axs[0].set_title('th = '+str(ps_choose['threshold'])+' , sigma = '+str(ps_choose['sigma']));\n",
    "plt.savefig(save_name+\"_ChossenClustering.png\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_clusterSizes_all,vars=[\"similarityScore\",\"clusterSize\"],hue='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all.to_csv(save_name+'clusterSizes_all.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(13,6)); \n",
    "\n",
    "sns.set_theme(style=\"white\");\n",
    "\n",
    "sns.histplot(data=df_clusterSizes_all,x='clusterSize',hue='type',ax=axs[0],element=\"step\", fill=False,kde=True);\n",
    "\n",
    "axs[0].set_xlim(0,700);\n",
    "axs[0].set_ylim(0,300);\n",
    "\n",
    "axs[1].set_ylim(0,600);\n",
    "axs[1].set_xlim(0,200);\n",
    "\n",
    "sns.histplot(data=df_clusterSizes_all,x='similarityScore',hue='type',ax=axs[1],kde=True, element=\"step\", fill=False);\n",
    "#axs[1].set_xlim(0,700);\n",
    "\n",
    "plt.savefig(save_name+\"_SizeAndSimilarity.png\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_clusterSizes_all,x='clusterSize',y='similarityScore',alpha=0.2,hue='type');\n",
    "plt.xlim(0,700);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all.groupby('type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 100;\n",
    "row = phasespace_all_aboveT.loc[idx,:];\n",
    "#row = phasespace_all.loc[idx,:];\n",
    "\n",
    "labels_incell = row['labels'];\n",
    "labels_outcell  = row['labels_ref'];\n",
    "fig,axs = plt.subplots(1,2,figsize=(13,8)); \n",
    "PlotScatter(XC_incell,labels_incell,ax=axs[0])\n",
    "PlotScatter(XC_outcell,labels_outcell,ax=axs[1])\n",
    "axs[0].set_title('th = '+str(phasespace_all.loc[idx,'threshold'])+\\\n",
    "                 ' , sig = '+str(phasespace_all.loc[idx,'sigma'])+' , '+\\\n",
    "                 str(len(np.unique(labels_incell))-1)+' clusters');\n",
    "\n",
    "axs[1].set_title('th = '+str(phasespace_all.loc[idx,'threshold'])+\\\n",
    "                 ' , sig = '+str(phasespace_all.loc[idx,'sigma'])+' , '+\\\n",
    "                 str(len(np.unique(labels_outcell))-1)+' clusters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(14,6));\n",
    "\n",
    "ax = axs[0];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all_aboveT, values='percent_locsIncluded', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax,vmax=1);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('percent_locsIncluded_aboveT');\n",
    "\n",
    "ax = axs[1];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all_aboveT, values='percent_locsIncluded_ref', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax,vmax=1.);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('percent_locsIncluded_aboveT_ref');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not useful -- wanted to check whether \n",
    "phasespace_all_aboveT['no_cl_in_vs_out'] = phasespace_all_aboveT['no_clusters']/phasespace_all_aboveT['no_clusters_ref'];\n",
    "\n",
    "fig,axs = plt.subplots(1,1,figsize=(6,6));\n",
    "\n",
    "ax = axs;\n",
    "heatmap1_data = pd.pivot_table(phasespace_all_aboveT, values='no_cl_in_vs_out', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax,vmax=3);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('percent_locsIncluded_aboveT');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phasespace_all_aboveT.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(14,6));\n",
    "\n",
    "ax = axs[0];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no_clusters');\n",
    "\n",
    "ax = axs[1];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all_aboveT, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('no_clusters above T');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(14,6));\n",
    "\n",
    "ax = axs[0];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore');\n",
    "\n",
    "ax = axs[1];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all_aboveT, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax,);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore above T');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_th_aboveT_ncl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cli_similarityScore,similarityScore,similarityScoreMatrix = getSimilarityScoreH(XC_incell,phasespace_all_aboveT,clusterInfo_aboveT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_check = 56;\n",
    "v = [];\n",
    "for i in np.arange(len(phasespace_all_aboveT)):\n",
    "    s1= getSimilarityScore_ij(i_check,i,phasespace_all_aboveT,clusterInfo_aboveT)\n",
    "#    print(s1)\n",
    "        \n",
    "    if(type(s1)!= bool):\n",
    "        v.append(np.sum(s1[0]));\n",
    "    else:\n",
    "        v.append(0);\n",
    " #       print(np.sum(s1[0]),np.sum(s1[1]));\n",
    "phasespace_all_aboveT['v'] = v;\n",
    "print(np.sum(v))\n",
    "print(v)\n",
    "\n",
    "\n",
    "print(similarityScoreMatrix[i_check,:])\n",
    "print(similarityScoreMatrix[i_check,i_check])\n",
    "print(np.max(abs(similarityScoreMatrix[i_check,:]-v)))\n",
    "print(np.argmax(abs(similarityScoreMatrix[i_check,:]-v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(14,6));\n",
    "\n",
    "ax = axs[0];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all_aboveT, values='similarityScore', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('similarityScore');\n",
    "\n",
    "ax = axs[1];\n",
    "heatmap1_data = pd.pivot_table(phasespace_all_aboveT, values='v', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=ax);\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('v');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix,axs=plt.subplots(2,2,figsize=(10,10))\n",
    "\n",
    "axs[0,0].plot(df_opt_th_aboveT_ncl['threshold'],df_opt_th_aboveT_ncl['no_clusters'])\n",
    "axs[0,1].plot(df_opt_th_ncl['threshold'],df_opt_th_ncl['no_clusters'])\n",
    "\n",
    "axs[1,0].plot(df_opt_th_aboveT_ncl['threshold'],df_opt_th_aboveT_ncl['similarityScore'])\n",
    "axs[1,1].plot(df_opt_th_ncl['threshold'],df_opt_th_ncl['similarityScore'])\n",
    "\n",
    "axs[0,0].set_ylim(0,8.5);\n",
    "axs[0,1].set_ylim(0,700);\n",
    "\n",
    "axs[1,0].set_ylim(0,550);\n",
    "axs[1,1].set_ylim(0,7000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 13;\n",
    "\n",
    "df_incell = df_clusterSizes_all_opt[(df_clusterSizes_all_opt['threshold']==threshold)*\\\n",
    "                (df_clusterSizes_all_opt['type']=='incell')];\n",
    "df_outcell  = df_clusterSizes_all_opt[(df_clusterSizes_all_opt['threshold']==threshold)*\\\n",
    "                (df_clusterSizes_all_opt['type']=='outcell')];\n",
    "GetOptimalT(df_incell,df_outcell,criterion='similarityScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_th_aboveT_ncl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotAllClustersAlongOptimum(df_opt,phasespace,name):\n",
    "    for idx,row in df_opt.iterrows():\n",
    "        row_ps = phasespace.loc[row['idx'],:];\n",
    "\n",
    "        sigma = row['sigma'];\n",
    "        threshold = row['threshold'];\n",
    "\n",
    "        fig,axs = plt.subplots(1,2,figsize=(13,8)); \n",
    "        PlotScatter(XC_incell,row_ps['labels'],ax=axs[0])\n",
    "        PlotScatter(XC_outcell,row_ps['labels_ref'],ax=axs[1])\n",
    "        if('T' in phasespace.columns):\n",
    "            axs[0].set_title('in cell for clusters with size > '+str(row_ps['T'])+' , '+str(len(np.unique(row_ps['labels']))-1)+' clusters');\n",
    "            axs[1].set_title('out cell for clusters with size > '+str(row_ps['T'])+' , '+str(len(np.unique(row_ps['labels_ref']))-1)+' clusters');\n",
    "        else:\n",
    "            axs[0].set_title('in cell for '+str(len(np.unique(row_ps['labels']))-1)+' clusters');\n",
    "            axs[1].set_title('out cell for ' +str(len(np.unique(row_ps['labels_ref']))-1)+' clusters');            \n",
    "\n",
    "        #axs[1].set_ylim([57500,62500]);\n",
    "        #axs[1].set_xlim([55000,60000]);\n",
    "\n",
    "        if(False): \n",
    "            axs[0].axis('off');\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            axs[0].set_title('Inside of cell');\n",
    "            axs[1].set_title('Reference -- Outside of cell');\n",
    "\n",
    "        plt.savefig(save_name+\"_OptimalClustering_split_threshold_\"+str(threshold)+\"_\"+name+\".png\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotAllClustersAlongOptimum(df_opt_th_aboveT_ncl,phasespace_all_aboveT,'aboveT');\n",
    "PlotAllClustersAlongOptimum(df_opt_th_ncl,phasespace_all,'');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df_clusterSizes_all_opt[df_clusterSizes_all_opt['threshold']==25], x=\"clusterSize\",hue='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "def fit_function(k, lamb):\n",
    "    '''poisson function, parameter lamb is the fit parameter'''\n",
    "    return poisson.pmf(k, lamb)\n",
    "    \n",
    "def fit_function_nb(k,n,p):\n",
    "    '''poisson function, parameter lamb is the fit parameter'''\n",
    "    return nbinom.pmf(k, n,p)\n",
    "    \n",
    "    \n",
    "def GetPoissonParameters(data):\n",
    "    # the bins should be of integer width, because poisson is an integer distribution\n",
    "    bins = np.round(np.linspace(0,100,20));#np.arange(100) - 0.5\n",
    "    entries, bin_edges, patches = plt.hist(data, bins=bins, density=True, label='Data');\n",
    "\n",
    "    # calculate bin centres\n",
    "    bin_middles = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "    # fit with curve_fit\n",
    "    parameters, cov_matrix = curve_fit(fit_function_nb, bin_middles, entries)\n",
    "    return parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.arange(600)\n",
    "np.sum(x_plot*fit_function_nb(x_plot,r,1-p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_max = 200;\n",
    "\n",
    "mark = (df_clusterSizes_all['threshold']==11)*(df_clusterSizes_all['type']=='noise')\n",
    "data = np.array(df_clusterSizes_all.loc[mark,'clusterSize'])\n",
    "\n",
    "data = data[data < data_max]\n",
    "\n",
    "E,V = np.mean(data),np.var(data);\n",
    "r = E**2/(V-E);\n",
    "p = 1-E/V;\n",
    "\n",
    "print('r :',r,' p: ',p);\n",
    "\n",
    "# plot poisson-deviation with fitted parameter\n",
    "bins = np.round(np.linspace(1,data_max,20));#np.arange(100) - 0.5\n",
    "x_plot = np.round(np.linspace(1,data_max,20));#np.arange(100);\n",
    "\n",
    "plt.hist(data, bins=bins, density=True, label='Data');\n",
    "plt.plot(\n",
    "    x_plot,\n",
    "    fit_function_nb(x_plot,r,1-p),\n",
    "    marker='o', linestyle='',\n",
    "    label='Fit result',\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bins should be of integer width, because poisson is an integer distribution\n",
    "bins = np.round(np.linspace(1,100,20));#np.arange(100) - 0.5\n",
    "entries, bin_edges, patches = plt.hist(data, bins=bins, density=True, label='Data');\n",
    "\n",
    "# calculate bin centres\n",
    "bin_middles = np.round(0.5 * (bin_edges[1:] + bin_edges[:-1]))\n",
    "\n",
    "# fit with curve_fit\n",
    "parameters, cov_matrix = curve_fit(fit_function_nb, bin_middles, entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "\n",
    "bins = np.linspace(0,100,20);\n",
    "entries, bin_edges, patches = plt.hist(data, bins=bins, density=True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get poisson deviated random numbers\n",
    "#data = np.random.poisson(2, 1000)\n",
    "mark = (df_clusterSizes_all['threshold']==11)*(df_clusterSizes_all['type']=='incell')\n",
    "data = np.array(df_clusterSizes_all.loc[mark,'clusterSize'])\n",
    "parameters = GetPoissonParameters(data)\n",
    "print(parameters)\n",
    "\n",
    "# plot poisson-deviation with fitted parameter\n",
    "x_plot = np.round(np.linspace(1,100,20));#np.arange(100);\n",
    "\n",
    "plt.plot(\n",
    "    x_plot,\n",
    "    fit_function_nb(x_plot,10,0.3),\n",
    "    marker='o', linestyle='',\n",
    "    label='Fit result',\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all.query('clusterSize < 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all.query('clusterSize < 100').groupby(by=['threshold','type']).agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusterSizes_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_clusterSizes['type']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_stats_per_th = AnalyseClusterSizes(df_clusterSizes,df_clusterSizes_ref,save_name+\"_phasespace_alongLineOfOptima.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(12,6))\n",
    "sns.lineplot(data=df_stats_per_th,x='threshold',y='quantile_90',hue='type',ax=axs[0]);\n",
    "sns.lineplot(data=df_stats_per_th,x='threshold',y='n',hue='type',ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in np.unique(df_opt_th['threshold']):\n",
    "    idx_ = int(df_opt_th.loc[df_opt_th['threshold']==th,'idx'])\n",
    "\n",
    "    fig,axs = plt.subplots(1,2,figsize=(13,8)); \n",
    "    PlotScatter(XC_incell,FD.phasespace.loc[idx_,'labels'],ax=axs[0])\n",
    "    PlotScatter(XC_outcell,FD_ref.phasespace.loc[idx_,'labels'],ax=axs[1])\n",
    "    axs[0].set_title('in cell');\n",
    "    axs[1].set_title('out cell');\n",
    "    \n",
    "    #axs[1].set_ylim([50,70]);\n",
    "    #axs[1].set_xlim([50,70]);\n",
    "    \n",
    "    if(True): \n",
    "        axs[0].axis('off');\n",
    "        axs[1].axis('off')\n",
    "    \n",
    "        axs[0].set_title('Inside of cell');\n",
    "        axs[1].set_title('Reference -- Outside of cell');\n",
    "    \n",
    "    plt.savefig(save_name+\"_OptimalClustering_threshold_\"+str(th)+\".png\",bbox_inches=\"tight\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse signal vs noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='similarityScore_ref',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'similarityScore_ref'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'similarityScore_ref'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "sns.lineplot(data=df_opt_sim,x='similarityScore_ref',y=\"similarityScore\",color='r',ax=ax)\n",
    "sns.lineplot(data=df_opt_cl,x='similarityScore_ref',y=\"similarityScore\",color='b',ax=ax)\n",
    "ax.set_title('ordered by similarity score');\n",
    "\n",
    "ax      = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "sns.lineplot(data=df_opt_sim,x='no_clusters_ref',y=\"no_clusters\",ax=ax,color='r')\n",
    "sns.lineplot(data=df_opt_cl,x='no_clusters_ref',y=\"no_clusters\",ax=ax,color='b')\n",
    "ax.set_title('ordered by no of clusters');\n",
    "\n",
    "plt.savefig(save_name+\"_phasespace_ordered.pdf\",bbox_inches=\"tight\");\n",
    "#ax.set_xlim(-10,2000);\n",
    "#ax.set_xlim(0,30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='similarityScore_ref_ratio',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'similarityScore_ref_ratio'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'similarityScore_ref_ratio'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "ax.set_xlim(0,1);\n",
    "#ax.set_ylim(-10,4000);\n",
    "\n",
    "ax = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref_ratio',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref_ratio'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref_ratio'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "ax.set_xlim(0,0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(15,7));\n",
    "\n",
    "ax      = axs[0];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"similarityScore\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'similarityScore'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'similarityScore'],c='b',marker='s');\n",
    "#ax.set_xlim(-10,2000);\n",
    "#ax.set_ylim(-10,4000);\n",
    "\n",
    "ax = axs[1];\n",
    "sns.scatterplot(data=df1,x='no_clusters_ref',y=\"no_clusters\",hue='sigma',size='threshold',ax=ax);\n",
    "#ax.scatter(df1.loc[idx_similarityScore,'no_clusters_ref'],df1.loc[idx_similarityScore,'no_clusters'],c='r',marker='s');\n",
    "#ax.scatter(df1.loc[idx_no_clusters,'no_clusters_ref'],df1.loc[idx_no_clusters,'no_clusters'],c='b',marker='s');\n",
    "#ax.set_xlim(-1,20);\n",
    "#ax.set_ylim(-1,50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save for input in R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save phasespace in csv\n",
    "FD_all1 = (FD.phasespace);\n",
    "FD_all1['type'] = 'incell';\n",
    "\n",
    "FD_all2         = (FD_ref.phasespace);\n",
    "FD_all2['type'] = 'outcell';\n",
    "\n",
    "(FD_all1.append(FD_all2,ignore_index=True)).to_csv(outputfolder_R+'results_'+analysis_name+'.csv');\n",
    "#(FD.phasespace).to_csv(outputfolder+'results_phasespace'+analysis_name+'.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.zeros((len((FD.phasespace).loc[1,'labels']),len(FD.phasespace)),dtype=np.int32)\n",
    "for i,d in enumerate(FD.phasespace['labels']):\n",
    "    L[:,i] = d;\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_labels_incell.txt\",L,fmt=\"%d\",delimiter='\\t',newline='\\n');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.zeros((len((FD_ref.phasespace).loc[1,'labels']),len(FD_ref.phasespace)),dtype=np.int32)\n",
    "for i,d in enumerate(FD_ref.phasespace['labels']):\n",
    "    L[:,i] = d;\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_labels_outcell.txt\",L,fmt=\"%d\",delimiter='\\t',newline='\\n');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(outputfolder_R+analysis_name+\"_filtered_outcell.txt\",XC_outcell,fmt=\"%f\\t%f\");\n",
    "np.savetxt(outputfolder_R+analysis_name+\"_filtered_incell.txt\",XC_incell,fmt=\"%f\\t%f\");    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_distribution = [];\n",
    "ind = np.zeros((0,),dtype=int);\n",
    "for i,d in enumerate(FD.phasespace['labels']):\n",
    "    d_ = GetClusterDistribution(d);\n",
    "    cls_distribution += (d_);\n",
    "    ind = np.concatenate((ind,i*np.ones_like(d_,dtype=int)))\n",
    "    \n",
    "cls_d = pd.DataFrame();\n",
    "cls_d['size'] = cls_distribution\n",
    "cls_d['index'] = (ind);\n",
    "cls_d.to_csv(outputfolder_R+analysis_name+\"_clusterSizes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(outputfolder_R+analysis_name+\"_clusterSizes.txt\", \"w\") as txt_file:\n",
    "#    for i,d in enumerate(FD.phasespace['labels']):\n",
    "#        d_ = GetClusterDistribution(d);\n",
    "#        txt_file.write(' '.join(str(x) for x in d_)+'\\n') # works with any number of el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a clustering:\n",
    "if(False):\n",
    "    limit_outcell_to_incell = 0.4;\n",
    "    \n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['similarityScore_ref_ratio'] < limit_outcell_to_incell);\n",
    "    idx_similarityScore  = (df1.loc[mark_,'similarityScore']).idxmax();\n",
    "#    print(df1.loc[idx_similarityScore,:])\n",
    "\n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['no_clusters_ref_ratio'] < limit_outcell_to_incell);\n",
    "    idx_no_clusters  = (df1.loc[mark_,'no_clusters']).idxmax();\n",
    "#    print(df1.loc[idx_no_clusters,:])\n",
    "else:\n",
    "    limit_outcell_no_cluster = 4;    \n",
    "    limit_outcell_similarity = 320;\n",
    "        \n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['similarityScore_ref'] < limit_outcell_similarity);\n",
    "    idx_similarityScore  = (df1.loc[mark_,'similarityScore']).idxmax();\n",
    "#    print(df1.loc[idx_similarityScore,:])\n",
    "\n",
    "    # (1) based on number of clusters\n",
    "    mark_ = (df1['no_clusters_ref'] < limit_outcell_no_cluster);\n",
    "    idx_no_clusters  = (df1.loc[mark_,'no_clusters']).idxmax();\n",
    "#    print(df1.loc[idx_no_clusters,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,2,figsize=(13,13)); \n",
    "PlotScatter(XC_incell,FD.phasespace.loc[idx_similarityScore,'labels'],ax=axs[0,0])\n",
    "PlotScatter(XC_incell,FD.phasespace.loc[idx_no_clusters,'labels'],ax=axs[0,1])\n",
    "\n",
    "PlotScatter(XC_outcell,FD_ref.phasespace.loc[idx_similarityScore,'labels'],ax=axs[1,0])\n",
    "PlotScatter(XC_outcell,FD_ref.phasespace.loc[idx_no_clusters,'labels'],ax=axs[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: Did we reach a plateau?\n",
    "def Plateau_analysis(x,y):    \n",
    "    x =np.asarray(x);\n",
    "    y =np.asarray(y);    \n",
    "    \n",
    "    y = 0.5*(y[1:]+y[:-1]);\n",
    "    x = 0.5*(x[1:]+x[:-1]);    \n",
    "    \n",
    "    dydx = (y[1:]-y[:-1])/(x[1:]-x[:-1]);\n",
    "#    print(dydx)\n",
    "#    print(y)\n",
    "    plt.plot(x[1:],dydx/y[0],'r');\n",
    "#    plt.plot(x,y,'b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plateau_analysis(df_stats_per_th['threshold'],df_stats_per_th['firstBin'])\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df_stats_per_th['kurtosis'];\n",
    "sns.lineplot(df_stats_per_th['threshold'][1:],np.abs(np.asarray(z[1:])-np.asarray(z[:-1])),label='kurtosis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(np.max(df_clusterSizes['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_clusterSizes.loc[df_clusterSizes['threshold']==11,'clusterSize'],bins=np.linspace(0,100,101)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_opt_sim['sigma'],df_opt_sim['threshold']);\n",
    "sns.scatterplot(x=df_opt_sim['sigma'],y=df_opt_sim['threshold'],hue=df_opt_sim['similarityScore'],s=100);\n",
    "plt.xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "plt.ylim(np.min(df1['threshold']),np.max(df1['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_opt_cl['sigma'],df_opt_cl['threshold']);\n",
    "sns.scatterplot(x=df_opt_cl['sigma'],y=df_opt_cl['threshold'],hue=df_opt_cl['no_clusters'],s=100);\n",
    "plt.xlim(np.min(df1['sigma']),np.max(df1['sigma']))\n",
    "plt.ylim(np.min(df1['threshold']),np.max(df1['threshold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['no_clusters_diff'] = np.asarray(df1.loc[:,'no_clusters'])-np.asarray(df1_ref.loc[:,'no_clusters'])\n",
    "df1 = df1.fillna(0)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,5));\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters_diff', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[0]);\n",
    "ax.invert_yaxis()\n",
    "\n",
    "heatmap1_data = pd.pivot_table(df1, values='no_clusters', \n",
    "                     index=['threshold'], \n",
    "                     columns='sigma')\n",
    "ax = sns.heatmap(heatmap1_data,ax=axs[1]);\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in np.unique(FD.phasespace['threshold']):\n",
    "    mark = (FD.phasespace['threshold'] == th);\n",
    "    PS_sel = FD.phasespace.loc[mark,:];\n",
    "    idx_max = PS_sel['similarityScore'].idxmax();\n",
    "    PlotScatter(XC_incell,PS_sel.loc[idx_max,'labels']);#,str(th));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PS_sel.loc[:,'labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the kl divergence\n",
    "def kl_divergence(p, q):\n",
    "    return sum(p[i] * np.log2(p[i]/q[i]) for i in range(len(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCLDist(th):\n",
    "    data = df_clusterSizes[df_clusterSizes['threshold']==th].loc[:,'clusterSize'];\n",
    "    bin_no = (np.histogram(data, bins)[0])/np.sum(np.histogram(data, bins)[0]);\n",
    "    return bin_no;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetCLDist(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,50,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(data, bins,weights=data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divergence(GetCLDist(3),GetCLDist(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
